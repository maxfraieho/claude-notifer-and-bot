#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
–†–æ–∑—à–∏—Ä–µ–Ω–∏–π –ê—É–¥–∏—Ç–æ—Ä –õ–æ–≥—ñ–∫–∏ Telegram –ë–æ—Ç–∞ (–¥–ª—è Claude Code Telegram Bot)
–§–æ–∫—É—Å: –†–µ–∞–ª—å–Ω—ñ –ø—Ä–æ–±–ª–µ–º–∏ –¥–æ—Å–≤—ñ–¥—É –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞ (UX), –æ—Å–æ–±–ª–∏–≤–æ –¥–ª—è —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—ó –ª–æ–∫–∞–ª—ñ–∑–∞—Ü—ñ—ó

–ê–≤—Ç–æ—Ä: AI –ê—Å–∏—Å—Ç–µ–Ω—Ç
–ú–æ–≤–∞ –∑–≤—ñ—Ç—ñ–≤: –£–∫—Ä–∞—ó–Ω—Å—å–∫–∞
"""

import os
import re
import ast
import json
import logging
from pathlib import Path
from typing import Dict, List, Set, Tuple, Optional, Any
from datetime import datetime
import sys

# –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –ª–æ–≥—É–≤–∞–Ω–Ω—è
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class AdvancedBotAuditor:
    """–ì–æ–ª–æ–≤–Ω–∏–π –∫–ª–∞—Å –∞—É–¥–∏—Ç–æ—Ä–∞, —è–∫–∏–π –∞–Ω–∞–ª—ñ–∑—É—î –±–æ—Ç –Ω–∞ —Ä–µ–∞–ª—å–Ω—ñ –ø—Ä–æ–±–ª–µ–º–∏ UX."""

    def __init__(self, source_dir: str = "src", report_lang: str = "uk"):
        """
        –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—è –∞—É–¥–∏—Ç–æ—Ä–∞.

        :param source_dir: –®–ª—è—Ö –¥–æ –¥–∏—Ä–µ–∫—Ç–æ—Ä—ñ—ó –∑ –≤–∏—Ö—ñ–¥–Ω–∏–º –∫–æ–¥–æ–º (–∑–∞ –∑–∞–º–æ–≤—á—É–≤–∞–Ω–Ω—è–º "src")
        :param report_lang: –ú–æ–≤–∞ –∑–≤—ñ—Ç—É ("uk" –∞–±–æ "en")
        """
        self.source_dir = Path(source_dir)
        if not self.source_dir.exists():
            raise FileNotFoundError(f"–î–∏—Ä–µ–∫—Ç–æ—Ä—ñ—é {source_dir} –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ")

        self.report_lang = report_lang
        self.findings = {
            'critical': [],
            'localization': [],
            'ux': [],
            'integration': [],
            'buttons': []
        }

        # –®–ª—è—Ö–∏ –¥–æ —Ñ–∞–π–ª—ñ–≤ –ø–µ—Ä–µ–∫–ª–∞–¥—ñ–≤
        self.translations = {}
        self.translation_files = {
            'en': self.source_dir / "localization" / "translations" / "en.json",
            'uk': self.source_dir / "localization" / "translations" / "uk.json"
        }

        # –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω—ñ –∫–ª—é—á—ñ –ø–µ—Ä–µ–∫–ª–∞–¥—ñ–≤
        self.translation_keys = {'en': set(), 'uk': set()}

        # –ü–∞—Ç–µ—Ä–Ω–∏ –¥–ª—è –≤–∏—è–≤–ª–µ–Ω–Ω—è –∫—Ä–∏—Ç–∏—á–Ω–∏—Ö –ø—Ä–æ–±–ª–µ–º
        self.CRITICAL_PATTERNS = {
            'dead_commands': [
                r'@register_command\(["\'](\w+)["\'].*?async def.*?raise NotImplementedError',
                r'CommandHandler\(["\'](\w+)["\'].*?pass\b',
                r'reply_text\([rf]?["\'][^"\']*Error[^"\']*["\'].*?# TODO',
            ],
            'silent_failures': [
                r'except\s*:\s*pass(?!\s*#)',
                r'except\s*:\s*continue(?!\s*#)',
                r'try:.*?except.*?:\s*return\s+None',
            ],
            'user_facing_errors': [
                r'reply_text\([rf]?["\'][^"\']*(?:Exception|Error|Failed|Invalid|Timeout)[^"\']*["\']',
                r'await.*?reply.*?code\s*\d+',
            ],
            'broken_buttons': [
                r'InlineKeyboardButton\(["\']([^"\']+)["\'].*?callback_data=["\'](\w+)["\']'
            ]
        }

        # –ü–∞—Ç–µ—Ä–Ω–∏ –¥–ª—è –≤–∏—è–≤–ª–µ–Ω–Ω—è –ø—Ä–æ–±–ª–µ–º UX
        self.UX_PATTERNS = {
            'mixed_languages': [
                r'[–∞-—è—ñ—ó—î“ë–ê-–Ø–Ü–á–Ñ“ê]+.*?[a-zA-Z].*?reply_text',  # –£–∫—Ä–∞—ó–Ω—Å—å–∫–∏–π + –∞–Ω–≥–ª—ñ–π—Å—å–∫–∏–π —Ç–µ–∫—Å—Ç
                r'‚ùå.*?[A-Z][a-z]+.*?Error',  # –ê–Ω–≥–ª—ñ–π—Å—å–∫–∞ –ø–æ–º–∏–ª–∫–∞ –∑ —É–∫—Ä–∞—ó–Ω—Å—å–∫–∏–º –µ–º–æ–¥–∑—ñ
            ],
            'poor_error_messages': [
                r'reply_text\(["\']‚ùå[^"\']*["\'].*?\)',  # –ó–∞–≥–∞–ª—å–Ω—ñ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –ø–æ–º–∏–ª–æ–∫
                r'Exception.*?str\(e\)',  # –°–∏—Ä–∏–π —Ç–µ–∫—Å—Ç –≤–∏–∫–ª—é—á–µ–Ω–Ω—è
            ],
            'hardcoded_strings': [
                r'reply_text\([rf]?["\']([^"\']{10,}[^"\']*)["\']',  # –î–æ–≤–≥—ñ —Ä—è–¥–∫–∏ –≤ reply_text
                r'send_message\([rf]?["\']([^"\']{10,}[^"\']*)["\']',
            ]
        }

        # –í—ñ–¥–æ–º—ñ –∫–æ–º–∞–Ω–¥–∏, —è–∫—ñ –º–∞—é—Ç—å –±—É—Ç–∏ —Ä–µ–∞–ª—ñ–∑–æ–≤–∞–Ω—ñ (–∑ help —Ç–∞ —ñ–Ω—Ç–µ—Ä—Ñ–µ–π—Å—É)
        self.advertised_commands = {
            'start', 'help', 'new', 'continue', 'ls', 'cd', 'pwd', 'projects',
            'status', 'export', 'actions', 'git', 'schedules', 'add_schedule'
        }

        # –ö–µ—à AST –¥–ª—è —Ñ–∞–π–ª—ñ–≤
        self.ast_cache = {}

        # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ –ø–µ—Ä–µ–∫–ª–∞–¥–∏ –ø—Ä–∏ —ñ–Ω—ñ—Ü—ñ–∞–ª—ñ–∑–∞—Ü—ñ—ó
        self.load_translations()

    def load_translations(self):
        """–ó–∞–≤–∞–Ω—Ç–∞–∂—É—î —Ñ–∞–π–ª–∏ –ø–µ—Ä–µ–∫–ª–∞–¥—ñ–≤ —Ç–∞ –∑–±–∏—Ä–∞—î –≤—Å—ñ –∫–ª—é—á—ñ."""
        for lang, path in self.translation_files.items():
            try:
                with open(path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    self.translations[lang] = data
                    self.translation_keys[lang] = self._extract_all_keys(data)
                    logger.info(f"–ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ {lang} –ø–µ—Ä–µ–∫–ª–∞–¥–∏ –∑ {path}")
            except Exception as e:
                logger.error(f"–ù–µ –≤–¥–∞–ª–æ—Å—è –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ {lang} –ø–µ—Ä–µ–∫–ª–∞–¥–∏: {e}")
                self.translations[lang] = {}
                self.translation_keys[lang] = set()

    def _extract_all_keys(self, data: Any, prefix: str = "") -> Set[str]:
        """–†–µ–∫—É—Ä—Å–∏–≤–Ω–æ –≤–∏—Ç—è–≥—É—î –≤—Å—ñ –∫–ª—é—á—ñ –∑ JSON-—Å—Ç—Ä—É–∫—Ç—É—Ä–∏."""
        keys = set()
        if isinstance(data, dict):
            for key, value in data.items():
                full_key = f"{prefix}.{key}" if prefix else key
                keys.add(full_key)
                keys.update(self._extract_all_keys(value, full_key))
        return keys

    def scan_all_files(self):
        """–°–∫–∞–Ω—É—î –≤—Å—ñ Python-—Ñ–∞–π–ª–∏ –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä—ñ—ó —Ç–∞ –∑–∞–ø—É—Å–∫–∞—î –º–æ–¥—É–ª—ñ –∞—É–¥–∏—Ç—É."""
        logger.info("–ü–æ—á–∞—Ç–æ–∫ –ø–æ–≤–Ω–æ–≥–æ –∞—É–¥–∏—Ç—É...")
        python_files = list(self.source_dir.rglob("*.py"))

        for file_path in python_files:
            logger.info(f"–ê–Ω–∞–ª—ñ–∑ —Ñ–∞–π–ª—É: {file_path}")
            try:
                self.analyze_file(file_path)
            except Exception as e:
                logger.error(f"–ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª—ñ–∑—ñ {file_path}: {e}")

        # –î–æ–¥–∞—Ç–∫–æ–≤—ñ –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏
        self.check_advertised_commands()
        self.validate_localization_keys()

    def analyze_file(self, file_path: Path):
        """–ê–Ω–∞–ª—ñ–∑—É—î –æ–∫—Ä–µ–º–∏–π —Ñ–∞–π–ª –∑–∞ –¥–æ–ø–æ–º–æ–≥–æ—é AST —Ç–∞ —Ä–µ–≥—É–ª—è—Ä–Ω–∏—Ö –≤–∏—Ä–∞–∑—ñ–≤."""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                source_code = f.read()
                tree = ast.parse(source_code)
                self.ast_cache[file_path] = tree
        except Exception as e:
            logger.error(f"–ù–µ –≤–¥–∞–ª–æ—Å—è —Ä–æ–∑—ñ–±—Ä–∞—Ç–∏ AST –¥–ª—è {file_path}: {e}")
            return

        # 1. –ü–æ—à—É–∫ –∫—Ä–∏—Ç–∏—á–Ω–∏—Ö –ø—Ä–æ–±–ª–µ–º
        self._find_critical_issues(file_path, source_code)
        
        # 2. –ü–æ—à—É–∫ –ø—Ä–æ–±–ª–µ–º –ª–æ–∫–∞–ª—ñ–∑–∞—Ü—ñ—ó —Ç–∞ UX
        self._find_localization_and_ux_issues(file_path, source_code)
        
        # 3. –ê–Ω–∞–ª—ñ–∑ –∫–Ω–æ–ø–æ–∫
        self._analyze_buttons(file_path, source_code)

    def _find_critical_issues(self, file_path: Path, source_code: str):
        """–®—É–∫–∞—î –∫—Ä–∏—Ç–∏—á–Ω—ñ –ø—Ä–æ–±–ª–µ–º–∏: –º–µ—Ä—Ç–≤—ñ –∫–æ–º–∞–Ω–¥–∏, —Ç–∏—Ö—ñ –∑–±–æ—ó, –ø–æ–º–∏–ª–∫–∏ –¥–ª—è –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞."""
        for pattern_name, patterns in self.CRITICAL_PATTERNS.items():
            for pattern in patterns:
                for match in re.finditer(pattern, source_code, re.DOTALL):
                    issue = {
                        'file': str(file_path),
                        'line': source_code[:match.start()].count('\n') + 1,
                        'pattern_type': pattern_name,
                        'match': match.group(0),
                        'command_or_button': match.group(1) if len(match.groups()) > 0 else None
                    }
                    self.findings['critical'].append(issue)
                    logger.warning(f"–ö—Ä–∏—Ç–∏—á–Ω–∞ –ø—Ä–æ–±–ª–µ–º–∞ —É {file_path}:{issue['line']} - {pattern_name}")

    def _find_localization_and_ux_issues(self, file_path: Path, source_code: str):
        """–®—É–∫–∞—î –ø—Ä–æ–±–ª–µ–º–∏ –∑ –ª–æ–∫–∞–ª—ñ–∑–∞—Ü—ñ—î—é —Ç–∞ UX: –∑–º—ñ—à–∞–Ω—ñ –º–æ–≤–∏, –∂–æ—Ä—Å—Ç–∫–æ –∑–∞–∫–æ–¥–æ–≤–∞–Ω—ñ —Ä—è–¥–∫–∏."""
        # –ü–æ—à—É–∫ –∑–º—ñ—à–∞–Ω–∏—Ö –º–æ–≤
        for pattern in self.UX_PATTERNS['mixed_languages']:
            for match in re.finditer(pattern, source_code):
                issue = {
                    'file': str(file_path),
                    'line': source_code[:match.start()].count('\n') + 1,
                    'type': 'mixed_languages',
                    'snippet': match.group(0)
                }
                self.findings['localization'].append(issue)
                logger.info(f"–ó–º—ñ—à–∞–Ω–∞ –º–æ–≤–∞ —É {file_path}:{issue['line']}")

        # –ü–æ—à—É–∫ –∂–æ—Ä—Å—Ç–∫–æ –∑–∞–∫–æ–¥–æ–≤–∞–Ω–∏—Ö —Ä—è–¥–∫—ñ–≤
        for pattern in self.UX_PATTERNS['hardcoded_strings']:
            for match in re.finditer(pattern, source_code):
                text = match.group(1)
                # –Ü–≥–Ω–æ—Ä—É—î–º–æ —Ä—è–¥–∫–∏, —è–∫—ñ –≤–∏–≥–ª—è–¥–∞—é—Ç—å —è–∫ —à–ª—è—Ö–∏, –∑–º—ñ–Ω–Ω—ñ –∞–±–æ —Ç–µ—Ö–Ω—ñ—á–Ω—ñ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è
                if any(ignore in text for ignore in ['{', '}', '%s', '%d', 'http', '.py', '__']):
                    continue
                # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ, —á–∏ —Ü–µ –Ω–µ –∫–ª—é—á –ø–µ—Ä–µ–∫–ª–∞–¥—É (–Ω–µ –º—ñ—Å—Ç–∏—Ç—å –∫—Ä–∞–ø–æ–∫ –∞–±–æ –º–∞—î –ø—Ä–æ–±—ñ–ª–∏)
                if '.' not in text and ' ' in text:
                    issue = {
                        'file': str(file_path),
                        'line': source_code[:match.start()].count('\n') + 1,
                        'type': 'hardcoded_string',
                        'text': text
                    }
                    self.findings['localization'].append(issue)
                    logger.info(f"–ñ–æ—Ä—Å—Ç–∫–æ –∑–∞–∫–æ–¥–æ–≤–∞–Ω–∏–π —Ä—è–¥–æ–∫ —É {file_path}:{issue['line']} - '{text}'")

    def _analyze_buttons(self, file_path: Path, source_code: str):
        """–ê–Ω–∞–ª—ñ–∑—É—î –∫–Ω–æ–ø–∫–∏ —Ç–∞ —ó—Ö–Ω—ñ callback_data."""
        pattern = r'InlineKeyboardButton\(["\']([^"\']+)["\'].*?callback_data=["\']([^"\']+)["\']'
        for match in re.finditer(pattern, source_code):
            button_text = match.group(1)
            callback_data = match.group(2)
            line_num = source_code[:match.start()].count('\n') + 1

            # –¢–∏–º—á–∞—Å–æ–≤–æ –ø—Ä–∏–ø—É—Å–∫–∞—î–º–æ, —â–æ –≤—Å—ñ callback_data –º–∞—é—Ç—å –æ–±—Ä–æ–±–Ω–∏–∫–∏ (–ø–æ—Ç—Ä—ñ–±–Ω–∞ –≥–ª–∏–±—à–∞ –ø–µ—Ä–µ–≤—ñ—Ä–∫–∞)
            # –£ –º–∞–π–±—É—Ç–Ω—å–æ–º—É –º–æ–∂–Ω–∞ –¥–æ–¥–∞—Ç–∏ –ø–æ—à—É–∫ —Ñ—É–Ω–∫—Ü—ñ–π-–æ–±—Ä–æ–±–Ω–∏–∫—ñ–≤ –∑–∞ —ñ–º–µ–Ω–µ–º callback_data
            issue = {
                'file': str(file_path),
                'line': line_num,
                'button_text': button_text,
                'callback_data': callback_data,
                'status': 'assumed_working'  # –ü–æ—Ç—Ä—ñ–±–Ω–∞ –ø–æ–¥–∞–ª—å—à–∞ –ø–µ—Ä–µ–≤—ñ—Ä–∫–∞
            }
            self.findings['buttons'].append(issue)

    def check_advertised_commands(self):
        """–ü–µ—Ä–µ–≤—ñ—Ä—è—î, —á–∏ –≤—Å—ñ –æ–≥–æ–ª–æ—à–µ–Ω—ñ –∫–æ–º–∞–Ω–¥–∏ –º–∞—é—Ç—å —Ä–µ–∞–ª—ñ–∑–∞—Ü—ñ—é."""
        # –ó–Ω–∞—Ö–æ–¥–∏–º–æ –≤—Å—ñ –∑–∞—Ä–µ—î—Å—Ç—Ä–æ–≤–∞–Ω—ñ –∫–æ–º–∞–Ω–¥–∏ —É –∫–æ–¥—ñ
        implemented_commands = set()
        python_files = list(self.source_dir.rglob("*.py"))
        
        command_pattern = r'CommandHandler\(["\'](\w+)["\']'
        for file_path in python_files:
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                    for match in re.finditer(command_pattern, content):
                        implemented_commands.add(match.group(1))
            except Exception:
                continue

        # –ü–æ—Ä—ñ–≤–Ω—é—î–º–æ –∑ –æ–≥–æ–ª–æ—à–µ–Ω–∏–º–∏ –∫–æ–º–∞–Ω–¥–∞–º–∏
        for cmd in self.advertised_commands:
            if cmd not in implemented_commands:
                issue = {
                    'command': cmd,
                    'status': 'not_implemented',
                    'description': f"–ö–æ–º–∞–Ω–¥–∞ /{cmd} –æ–≥–æ–ª–æ—à–µ–Ω–∞ –≤ —ñ–Ω—Ç–µ—Ä—Ñ–µ–π—Å—ñ, –∞–ª–µ –Ω–µ –º–∞—î –æ–±—Ä–æ–±–Ω–∏–∫–∞"
                }
                self.findings['critical'].append(issue)
                logger.error(f"–ö–æ–º–∞–Ω–¥–∞ /{cmd} –Ω–µ —Ä–µ–∞–ª—ñ–∑–æ–≤–∞–Ω–∞!")

    def validate_localization_keys(self):
        """–ü–µ—Ä–µ–≤—ñ—Ä—è—î, —á–∏ –≤—Å—ñ –∫–ª—é—á—ñ –ø–µ—Ä–µ–∫–ª–∞–¥—É –ø—Ä–∏—Å—É—Ç–Ω—ñ –≤ –æ–±–æ—Ö –º–æ–≤–∞—Ö."""
        missing_in_uk = self.translation_keys['en'] - self.translation_keys['uk']
        missing_in_en = self.translation_keys['uk'] - self.translation_keys['en']

        for key in missing_in_uk:
            issue = {
                'key': key,
                'missing_in': 'uk',
                'type': 'missing_translation'
            }
            self.findings['localization'].append(issue)

        for key in missing_in_en:
            issue = {
                'key': key,
                'missing_in': 'en',
                'type': 'missing_translation'
            }
            self.findings['localization'].append(issue)

    def generate_report(self) -> str:
        """–ì–µ–Ω–µ—Ä—É—î –∑–≤—ñ—Ç –ø—Ä–æ –∑–Ω–∞—Ö—ñ–¥–∫–∏ —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—é –º–æ–≤–æ—é."""
        report_lines = []
        report_lines.append("# üéØ –†–û–ó–®–ò–†–ï–ù–ò–ô –ê–£–î–ò–¢ –î–û–°–í–Ü–î–£ –ö–û–†–ò–°–¢–£–í–ê–ß–ê\n")
        report_lines.append(f"**–ó–≥–µ–Ω–µ—Ä–æ–≤–∞–Ω–æ:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        report_lines.append(f"**–ü—Ä–æ–∞–Ω–∞–ª—ñ–∑–æ–≤–∞–Ω–æ —Ñ–∞–π–ª—ñ–≤:** {len(self.ast_cache)}\n\n")

        total_issues = sum(len(v) for v in self.findings.values())
        report_lines.append("## üìä –ó–ê–ì–ê–õ–¨–ù–ò–ô –ó–í–Ü–¢\n")
        report_lines.append(f"- **–í—Å—å–æ–≥–æ –ø—Ä–æ–±–ª–µ–º –∑–Ω–∞–π–¥–µ–Ω–æ:** {total_issues}\n")
        report_lines.append(f"- **–ö—Ä–∏—Ç–∏—á–Ω–∏—Ö (–±–ª–æ–∫—É—é—Ç—å –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞):** {len(self.findings['critical'])}\n")
        report_lines.append(f"- **–ü—Ä–æ–±–ª–µ–º –ª–æ–∫–∞–ª—ñ–∑–∞—Ü—ñ—ó:** {len(self.findings['localization'])}\n")
        report_lines.append(f"- **–ü—Ä–æ–±–ª–µ–º UX/—ñ–Ω—Ç–µ—Ä—Ñ–µ–π—Å—É:** {len(self.findings['ux']) + len(self.findings['buttons'])}\n")
        report_lines.append(f"- **–ü—Ä–æ–±–ª–µ–º —ñ–Ω—Ç–µ–≥—Ä–∞—Ü—ñ—ó:** {len(self.findings['integration'])}\n\n")

        if len(self.findings['critical']) > 0:
            report_lines.append("## üî¥ –ö–†–ò–¢–ò–ß–ù–Ü –ü–†–û–ë–õ–ï–ú–ò (–í–ò–ü–†–ê–í–ò–¢–ò –ù–ï–ì–ê–ô–ù–û)\n")
            for i, issue in enumerate(self.findings['critical'], 1):
                if 'command' in issue:
                    report_lines.append(f"### C{i}: –ù–ï–ü–†–ê–¶–Æ–Æ–ß–ê –ö–û–ú–ê–ù–î–ê\n")
                    report_lines.append(f"**–ü—Ä–æ–±–ª–µ–º–∞:** –ö–æ–º–∞–Ω–¥–∞ `/{issue['command']}` –æ–≥–æ–ª–æ—à–µ–Ω–∞, –∞–ª–µ –Ω–µ —Ä–µ–∞–ª—ñ–∑–æ–≤–∞–Ω–∞\n")
                    report_lines.append(f"**–©–æ –±–∞—á–∏—Ç—å –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á:** –ù–∞–±–∏—Ä–∞—î `/{issue['command']}` ‚Üí –æ—Ç—Ä–∏–º—É—î –ø–æ–º–∏–ª–∫—É –∞–±–æ –Ω—ñ—á–æ–≥–æ\n")
                    report_lines.append(f"**–†—ñ—à–µ–Ω–Ω—è:** –†–µ–∞–ª—ñ–∑—É–≤–∞—Ç–∏ –æ–±—Ä–æ–±–Ω–∏–∫ –∫–æ–º–∞–Ω–¥–∏ –∞–±–æ –ø—Ä–∏–±—Ä–∞—Ç–∏ –∑ –¥–æ–≤—ñ–¥–∫–∏/–º–µ–Ω—é\n\n")
                else:
                    report_lines.append(f"### C{i}: {issue.get('pattern_type', '–ù–µ–≤—ñ–¥–æ–º–∞ –ø—Ä–æ–±–ª–µ–º–∞')}\n")
                    report_lines.append(f"**–§–∞–π–ª:** `{issue['file']}` (—Ä—è–¥–æ–∫ {issue['line']})\n")
                    report_lines.append(f"**–ö–æ–¥:** `{issue['match']}`\n")
                    report_lines.append(f"**–†—ñ—à–µ–Ω–Ω—è:** –ü–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ –ª–æ–≥—ñ–∫—É –æ–±—Ä–æ–±–∫–∏ —Ç–∞ –¥–æ–¥–∞—Ç–∏ –∫–æ—Ä–µ–∫—Ç–Ω—É –≤—ñ–¥–ø–æ–≤—ñ–¥—å –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á—É\n\n")

        if len(self.findings['localization']) > 0:
            report_lines.append("## üåê –ü–†–û–ë–õ–ï–ú–ò –õ–û–ö–ê–õ–Ü–ó–ê–¶–Ü–á (–í–ò–ü–†–ê–í–ò–¢–ò –ù–ê –¶–¨–û–ú–£ –¢–ò–ñ–ù–Ü)\n")
            for i, issue in enumerate(self.findings['localization'], 1):
                if issue.get('type') == 'missing_translation':
                    report_lines.append(f"### L{i}: –í–Ü–î–°–£–¢–ù–Ü–ô –ü–ï–†–ï–ö–õ–ê–î\n")
                    report_lines.append(f"**–ö–ª—é—á:** `{issue['key']}`\n")
                    report_lines.append(f"**–í—ñ–¥—Å—É—Ç–Ω—ñ–π —É:** {issue['missing_in']}\n")
                    report_lines.append(f"**–†—ñ—à–µ–Ω–Ω—è:** –î–æ–¥–∞—Ç–∏ –ø–µ—Ä–µ–∫–ª–∞–¥ —É –≤—ñ–¥–ø–æ–≤—ñ–¥–Ω–∏–π JSON-—Ñ–∞–π–ª\n\n")
                elif issue.get('type') == 'hardcoded_string':
                    report_lines.append(f"### L{i}: –ñ–û–†–°–¢–ö–û –ó–ê–ö–û–î–û–í–ê–ù–ò–ô –†–Ø–î–û–ö\n")
                    report_lines.append(f"**–§–∞–π–ª:** `{issue['file']}` (—Ä—è–¥–æ–∫ {issue['line']})\n")
                    report_lines.append(f"**–¢–µ–∫—Å—Ç:** `{issue['text']}`\n")
                    report_lines.append(f"**–†—ñ—à–µ–Ω–Ω—è:** –í–∏–Ω–µ—Å—Ç–∏ —Ç–µ–∫—Å—Ç —É —Ñ–∞–π–ª–∏ –ø–µ—Ä–µ–∫–ª–∞–¥—ñ–≤ —Ç–∞ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–≤–∞—Ç–∏ —Ñ—É–Ω–∫—Ü—ñ—é –ª–æ–∫–∞–ª—ñ–∑–∞—Ü—ñ—ó\n\n")
                elif issue.get('type') == 'mixed_languages':
                    report_lines.append(f"### L{i}: –ó–ú–Ü–®–ê–ù–Ü –ú–û–í–ò\n")
                    report_lines.append(f"**–§–∞–π–ª:** `{issue['file']}` (—Ä—è–¥–æ–∫ {issue['line']})\n")
                    report_lines.append(f"**–§—Ä–∞–≥–º–µ–Ω—Ç:** `{issue['snippet']}`\n")
                    report_lines.append(f"**–†—ñ—à–µ–Ω–Ω—è:** –ü–µ—Ä–µ–∫–ª–∞—Å—Ç–∏ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è –ø–æ–≤–Ω—ñ—Å—Ç—é —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—é –∞–±–æ –∞–Ω–≥–ª—ñ–π—Å—å–∫–æ—é\n\n")

        if len(self.findings['buttons']) > 0:
            report_lines.append("## üéÆ –ü–†–û–ë–õ–ï–ú–ò –ó –ö–ù–û–ü–ö–ê–ú–ò\n")
            dead_buttons = [b for b in self.findings['buttons'] if b.get('status') == 'dead']
            for i, button in enumerate(dead_buttons, 1):
                report_lines.append(f"### B{i}: –ù–ï–ü–†–ê–¶–Æ–Æ–ß–ê –ö–ù–û–ü–ö–ê\n")
                report_lines.append(f"**–¢–µ–∫—Å—Ç –∫–Ω–æ–ø–∫–∏:** `{button['button_text']}`\n")
                report_lines.append(f"**Callback:** `{button['callback_data']}`\n")
                report_lines.append(f"**–§–∞–π–ª:** `{button['file']}` (—Ä—è–¥–æ–∫ {button['line']})\n")
                report_lines.append(f"**–†—ñ—à–µ–Ω–Ω—è:** –†–µ–∞–ª—ñ–∑—É–≤–∞—Ç–∏ –æ–±—Ä–æ–±–Ω–∏–∫ –∞–±–æ –ø—Ä–∏–±—Ä–∞—Ç–∏ –∫–Ω–æ–ø–∫—É\n\n")

        if total_issues == 0:
            report_lines.append("## üéâ –í–Ü–¢–ê–Ñ–ú–û!\n")
            report_lines.append("–ö—Ä–∏—Ç–∏—á–Ω–∏—Ö –ø—Ä–æ–±–ª–µ–º –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ. –ë–æ—Ç –≥–æ—Ç–æ–≤–∏–π –¥–æ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è!\n")

        return "\n".join(report_lines)

    def save_report(self, filename: str = "advanced_audit_report_ua.md"):
        """–ó–±–µ—Ä—ñ–≥–∞—î –∑–≤—ñ—Ç —É —Ñ–∞–π–ª."""
        report_content = self.generate_report()
        with open(filename, 'w', encoding='utf-8') as f:
            f.write(report_content)
        logger.info(f"–ó–≤—ñ—Ç –∑–±–µ—Ä–µ–∂–µ–Ω–æ —É {filename}")

    def get_quality_metrics(self) -> Dict[str, Any]:
        """–ü–æ–≤–µ—Ä—Ç–∞—î –º–µ—Ç—Ä–∏–∫–∏ —è–∫–æ—Å—Ç—ñ."""
        total_keys = len(self.translation_keys['en'])
        uk_coverage = len(self.translation_keys['uk']) / total_keys if total_keys > 0 else 0

        return {
            'localization_coverage_uk': f"{uk_coverage:.1%}",
            'critical_issues_count': len(self.findings['critical']),
            'hardcoded_strings_count': len([i for i in self.findings['localization'] if i.get('type') == 'hardcoded_string']),
            'missing_translations_uk': len([i for i in self.findings['localization'] if i.get('missing_in') == 'uk']),
            'advertised_commands_implemented': len(self.advertised_commands) - len([i for i in self.findings['critical'] if 'command' in i])
        }

    def run_full_audit(self):
        """–ó–∞–ø—É—Å–∫–∞—î –ø–æ–≤–Ω–∏–π –∞—É–¥–∏—Ç —ñ –∑–±–µ—Ä—ñ–≥–∞—î –∑–≤—ñ—Ç."""
        logger.info("üöÄ –ó–∞–ø—É—Å–∫ –ø–æ–≤–Ω–æ–≥–æ –∞—É–¥–∏—Ç—É...")
        self.scan_all_files()
        self.save_report()
        metrics = self.get_quality_metrics()
        logger.info("üìä –ú–µ—Ç—Ä–∏–∫–∏ —è–∫–æ—Å—Ç—ñ:")
        for key, value in metrics.items():
            logger.info(f"  {key}: {value}")
        logger.info("‚úÖ –ê—É–¥–∏—Ç –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")

if __name__ == "__main__":
    auditor = AdvancedBotAuditor(source_dir="src", report_lang="uk")
    auditor.run_full_audit()