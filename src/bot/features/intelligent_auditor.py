#!/usr/bin/env python3
"""
Intelligent Telegram Bot Auditor - Ğ¿Ğ¾Ñ”Ğ´Ğ½ÑƒÑ” ÑÑ‚Ğ°Ñ‚Ğ¸Ñ‡Ğ½Ğ¸Ğ¹ Ğ°Ğ½Ğ°Ğ»Ñ–Ğ· Ğ· Claude CLI Ñ–Ğ½Ñ‚ĞµĞ»ĞµĞºÑ‚Ğ¾Ğ¼
Ğ’Ğ¸ÑĞ²Ğ»ÑÑ” ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ½Ñ–, Ğ»Ğ¾Ğ³Ñ–Ñ‡Ğ½Ñ– Ñ‚Ğ° Ğ°Ñ€Ñ…Ñ–Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ½Ñ– Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ¸ Ğ² Telegram Ğ±Ğ¾Ñ‚Ğ°Ñ…
"""

import ast
import json
import os
import subprocess
import tempfile
from pathlib import Path
from typing import Dict, List, Set, Tuple, Union, Optional
from dataclasses import dataclass, asdict
from collections import defaultdict
import structlog

logger = structlog.get_logger(__name__)

@dataclass
class AuditIssue:
    category: str
    severity: str  # CRITICAL, HIGH, MEDIUM, LOW
    file_path: str
    line_number: int
    description: str
    code_snippet: str = ""
    fix_suggestion: str = ""
    claude_analysis: str = ""  # Ğ”Ğ¾Ğ´Ğ°Ñ‚ĞºĞ¾Ğ²Ğ¸Ğ¹ Ğ°Ğ½Ğ°Ğ»Ñ–Ğ· Ğ²Ñ–Ğ´ Claude
    group: str = ""  # Ğ“Ñ€ÑƒĞ¿Ğ° Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼ Ğ´Ğ»Ñ batch fixing

@dataclass
class AuditResult:
    total_issues: int
    critical_count: int
    high_count: int
    medium_count: int
    low_count: int
    issues: List[AuditIssue]
    claude_summary: str = ""
    recommendations: List[str] = None

    def __post_init__(self):
        if self.recommendations is None:
            self.recommendations = []

class IntelligentTelegramBotAuditor:
    """Ğ Ğ¾Ğ·ÑƒĞ¼Ğ½Ğ¸Ğ¹ Ğ°ÑƒĞ´Ğ¸Ñ‚Ğ¾Ñ€ Ğ´Ğ»Ñ Telegram Ğ±Ğ¾Ñ‚Ñ–Ğ² Ğ· Claude CLI Ñ–Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†Ñ–Ñ”Ñ"""

    def __init__(self, project_root: str, claude_integration=None):
        self.project_root = Path(project_root)
        self.claude_integration = claude_integration
        self.issues: List[AuditIssue] = []

        # Ğ”Ğ°Ğ½Ñ– Ğ´Ğ»Ñ Ğ°Ğ½Ğ°Ğ»Ñ–Ğ·Ñƒ
        self.translation_keys: Dict[str, Set[str]] = {}
        self.callback_handlers: Set[str] = set()
        self.button_callbacks: Set[str] = set()
        self.used_translation_keys: Set[str] = set()
        self.command_handlers: Set[str] = set()

        # ĞšĞ¾Ğ½Ñ„Ñ–Ğ³ÑƒÑ€Ğ°Ñ†Ñ–Ñ Ğ°Ğ½Ğ°Ğ»Ñ–Ğ·Ñƒ
        self.analysis_config = {
            "enable_claude_analysis": True,
            "claude_analysis_threshold": "HIGH",  # ĞœÑ–Ğ½Ñ–Ğ¼Ğ°Ğ»ÑŒĞ½Ğ° ÑĞµÑ€Ğ¹Ğ¾Ğ·Ğ½Ñ–ÑÑ‚ÑŒ Ğ´Ğ»Ñ Claude Ğ°Ğ½Ğ°Ğ»Ñ–Ğ·Ñƒ
            "group_similar_issues": True,
            "max_claude_calls": 10  # ĞĞ±Ğ¼ĞµĞ¶ĞµĞ½Ğ½Ñ Ğ²Ğ¸ĞºĞ»Ğ¸ĞºÑ–Ğ² Claude
        }

    async def run_audit(self, focus_area: Optional[str] = None) -> AuditResult:
        """Ğ—Ğ°Ğ¿ÑƒÑÑ‚Ğ¸Ñ‚Ğ¸ Ğ¿Ğ¾Ğ²Ğ½Ğ¸Ğ¹ Ğ°ÑƒĞ´Ğ¸Ñ‚ Ğ· Claude Ñ–Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†Ñ–Ñ”Ñ"""
        logger.info("Starting intelligent bot audit", project_root=str(self.project_root), focus_area=focus_area)

        # 1. Ğ¡Ñ‚Ğ°Ñ‚Ğ¸Ñ‡Ğ½Ğ¸Ğ¹ Ğ°Ğ½Ğ°Ğ»Ñ–Ğ· (Ğ½Ğ° Ğ±Ğ°Ğ·Ñ– Ñ–ÑĞ½ÑƒÑÑ‡Ğ¾Ğ³Ğ¾ ÑĞºÑ€Ğ¸Ğ¿Ñ‚Ğ°)
        await self._run_static_analysis(focus_area)

        # 2. Ğ“Ñ€ÑƒĞ¿ÑƒĞ²Ğ°Ğ½Ğ½Ñ ÑÑ…Ğ¾Ğ¶Ğ¸Ñ… Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼
        if self.analysis_config["group_similar_issues"]:
            self._group_similar_issues()

        # 3. Claude Ñ–Ğ½Ñ‚ĞµĞ»ĞµĞºÑ‚ÑƒĞ°Ğ»ÑŒĞ½Ğ¸Ğ¹ Ğ°Ğ½Ğ°Ğ»Ñ–Ğ·
        if self.analysis_config["enable_claude_analysis"] and self.claude_integration:
            await self._run_claude_analysis()

        # 4. Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ñ–Ñ Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ñ–Ğ¹
        recommendations = await self._generate_recommendations()

        # 5. ĞŸÑ–Ğ´Ğ³Ğ¾Ñ‚Ğ¾Ğ²ĞºĞ° Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñƒ
        result = self._prepare_audit_result(recommendations)

        logger.info("Audit completed",
                   total_issues=result.total_issues,
                   critical=result.critical_count,
                   high=result.high_count)

        return result

    async def _run_static_analysis(self, focus_area: Optional[str] = None):
        """Ğ—Ğ°Ğ¿ÑƒÑÑ‚Ğ¸Ñ‚Ğ¸ ÑÑ‚Ğ°Ñ‚Ğ¸Ñ‡Ğ½Ğ¸Ğ¹ Ğ°Ğ½Ğ°Ğ»Ñ–Ğ· ĞºĞ¾Ğ´Ñƒ"""
        logger.info("Running static analysis")

        # Ğ—Ğ°Ğ²Ğ°Ğ½Ñ‚Ğ°Ğ¶Ğ¸Ñ‚Ğ¸ Ğ¿ĞµÑ€ĞµĞºĞ»Ğ°Ğ´Ğ¸
        self._load_translation_keys()

        # Ğ—Ğ½Ğ°Ğ¹Ñ‚Ğ¸ Ğ²ÑÑ– Python Ñ„Ğ°Ğ¹Ğ»Ğ¸
        python_files = list(self.project_root.rglob("*.py"))

        for file_path in python_files:
            if self._should_skip_file(file_path):
                continue

            try:
                await self._analyze_python_file(file_path, focus_area)
            except Exception as e:
                self.issues.append(AuditIssue(
                    category="PARSING_ERROR",
                    severity="HIGH",
                    file_path=str(file_path),
                    line_number=0,
                    description=f"ĞŸĞ¾Ğ¼Ğ¸Ğ»ĞºĞ° Ğ¿Ğ°Ñ€ÑĞ¸Ğ½Ğ³Ñƒ Ñ„Ğ°Ğ¹Ğ»Ñƒ: {e}",
                    group="parsing_errors"
                ))

        # Ğ¡Ğ¿ĞµÑ†Ñ–Ğ°Ğ»ÑŒĞ½Ñ– Ğ¿ĞµÑ€ĞµĞ²Ñ–Ñ€ĞºĞ¸
        self._audit_callback_coverage()
        self._audit_translation_coverage()
        self._audit_architecture_issues()

    def _should_skip_file(self, file_path: Path) -> bool:
        """ĞŸĞµÑ€ĞµĞ²Ñ–Ñ€Ğ¸Ñ‚Ğ¸ Ñ‡Ğ¸ Ğ¿Ğ¾Ñ‚Ñ€Ñ–Ğ±Ğ½Ğ¾ Ğ¿Ñ€Ğ¾Ğ¿ÑƒÑÑ‚Ğ¸Ñ‚Ğ¸ Ñ„Ğ°Ğ¹Ğ»"""
        skip_patterns = ["venv", "__pycache__", ".git", "node_modules", ".pytest_cache"]
        return any(pattern in str(file_path) for pattern in skip_patterns)

    async def _analyze_python_file(self, file_path: Path, focus_area: Optional[str] = None):
        """ĞŸÑ€Ğ¾Ğ°Ğ½Ğ°Ğ»Ñ–Ğ·ÑƒĞ²Ğ°Ñ‚Ğ¸ Ğ¾Ğ´Ğ¸Ğ½ Python Ñ„Ğ°Ğ¹Ğ»"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
                lines = content.split('\n')

            tree = ast.parse(content)

            # Ğ Ñ–Ğ·Ğ½Ñ– Ñ‚Ğ¸Ğ¿Ğ¸ Ğ°Ğ½Ğ°Ğ»Ñ–Ğ·Ñƒ Ğ·Ğ°Ğ»ĞµĞ¶Ğ½Ğ¾ Ğ²Ñ–Ğ´ focus_area
            if not focus_area or focus_area == "callbacks":
                self._check_callback_handlers(tree, file_path, lines)
                self._check_button_callback_consistency(tree, file_path, lines)

            if not focus_area or focus_area == "localization":
                self._check_translation_usage(tree, file_path, lines)
                self._check_hardcoded_strings(file_path, lines)

            if not focus_area or focus_area == "security":
                self._check_security_issues(tree, file_path, lines)

            if not focus_area or focus_area == "architecture":
                self._check_architecture_patterns(tree, file_path, lines)

        except Exception as e:
            logger.error("Failed to analyze file", file_path=str(file_path), error=str(e))

    def _check_callback_handlers(self, tree: ast.AST, file_path: Path, lines: List[str]):
        """ĞŸĞµÑ€ĞµĞ²Ñ–Ñ€Ğ¸Ñ‚Ğ¸ callback handlers (Ñ€Ğ¾Ğ·ÑˆĞ¸Ñ€ĞµĞ½Ğ° Ğ²ĞµÑ€ÑÑ–Ñ)"""
        for node in ast.walk(tree):
            if isinstance(node, ast.FunctionDef):
                if node.name.endswith('_callback') or 'callback' in node.name:
                    self.callback_handlers.add(node.name)

                    # ĞŸĞµÑ€ĞµĞ²Ñ–Ñ€Ğ¸Ñ‚Ğ¸ Ñ‡Ğ¸ Ñ” await query.answer()
                    has_answer = False
                    for subnode in ast.walk(node):
                        if (isinstance(subnode, ast.Call) and
                            isinstance(subnode.func, ast.Attribute) and
                            subnode.func.attr == 'answer'):
                            has_answer = True
                            break

                    if not has_answer:
                        self.issues.append(AuditIssue(
                            category="CALLBACK_NO_ANSWER",
                            severity="MEDIUM",
                            file_path=str(file_path),
                            line_number=getattr(node, 'lineno', 0),
                            description=f"Callback {node.name} Ğ½Ğµ Ğ²Ğ¸ĞºĞ»Ğ¸ĞºĞ°Ñ” query.answer()",
                            code_snippet=lines[getattr(node, 'lineno', 1) - 1] if lines else "",
                            fix_suggestion="Ğ”Ğ¾Ğ´Ğ°Ñ‚Ğ¸ await query.answer() Ğ½Ğ° Ğ¿Ğ¾Ñ‡Ğ°Ñ‚Ğ¾Ğº callback Ñ„ÑƒĞ½ĞºÑ†Ñ–Ñ—",
                            group="callback_missing_answer"
                        ))

    def _check_security_issues(self, tree: ast.AST, file_path: Path, lines: List[str]):
        """ĞŸĞµÑ€ĞµĞ²Ñ–Ñ€Ğ¸Ñ‚Ğ¸ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ¸ Ğ±ĞµĞ·Ğ¿ĞµĞºĞ¸"""
        for node in ast.walk(tree):
            # ĞŸĞµÑ€ĞµĞ²Ñ–Ñ€Ğ¸Ñ‚Ğ¸ SQL injection Ğ¼Ğ¾Ğ¶Ğ»Ğ¸Ğ²Ğ¾ÑÑ‚Ñ–
            if isinstance(node, ast.Call):
                if (isinstance(node.func, ast.Attribute) and
                    node.func.attr in ['execute', 'query']):

                    # ĞŸĞµÑ€ĞµĞ²Ñ–Ñ€Ğ¸Ñ‚Ğ¸ Ñ‡Ğ¸ Ğ²Ğ¸ĞºĞ¾Ñ€Ğ¸ÑÑ‚Ğ¾Ğ²ÑƒÑ”Ñ‚ÑŒÑÑ string formatting Ğ² SQL
                    for arg in node.args:
                        if isinstance(arg, ast.BinOp) and isinstance(arg.op, ast.Mod):
                            self.issues.append(AuditIssue(
                                category="SQL_INJECTION_RISK",
                                severity="CRITICAL",
                                file_path=str(file_path),
                                line_number=getattr(node, 'lineno', 0),
                                description="ĞœĞ¾Ğ¶Ğ»Ğ¸Ğ²Ğ¸Ğ¹ SQL injection Ñ‡ĞµÑ€ĞµĞ· string formatting",
                                code_snippet=lines[getattr(node, 'lineno', 1) - 1] if lines else "",
                                fix_suggestion="Ğ’Ğ¸ĞºĞ¾Ñ€Ğ¸ÑÑ‚Ğ¾Ğ²ÑƒĞ²Ğ°Ñ‚Ğ¸ parameterized queries",
                                group="security_sql"
                            ))

    def _check_architecture_patterns(self, tree: ast.AST, file_path: Path, lines: List[str]):
        """ĞŸĞµÑ€ĞµĞ²Ñ–Ñ€Ğ¸Ñ‚Ğ¸ Ğ°Ñ€Ñ…Ñ–Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ½Ñ– Ğ¿Ğ°Ñ‚Ñ‚ĞµÑ€Ğ½Ğ¸"""
        # ĞŸĞµÑ€ĞµĞ²Ñ–Ñ€Ğ¸Ñ‚Ğ¸ Ğ²ĞµĞ»Ğ¸ĞºÑ– Ñ„ÑƒĞ½ĞºÑ†Ñ–Ñ—
        for node in ast.walk(tree):
            if isinstance(node, ast.FunctionDef):
                func_lines = getattr(node, 'end_lineno', 0) - getattr(node, 'lineno', 0)
                if func_lines > 50:
                    self.issues.append(AuditIssue(
                        category="LARGE_FUNCTION",
                        severity="MEDIUM",
                        file_path=str(file_path),
                        line_number=getattr(node, 'lineno', 0),
                        description=f"Ğ¤ÑƒĞ½ĞºÑ†Ñ–Ñ {node.name} Ğ·Ğ°Ğ½Ğ°Ğ´Ñ‚Ğ¾ Ğ²ĞµĞ»Ğ¸ĞºĞ° ({func_lines} Ñ€ÑĞ´ĞºÑ–Ğ²)",
                        fix_suggestion="Ğ Ğ¾Ğ·Ğ±Ğ¸Ñ‚Ğ¸ Ñ„ÑƒĞ½ĞºÑ†Ñ–Ñ Ğ½Ğ° Ğ¼ĞµĞ½ÑˆÑ– Ñ‡Ğ°ÑÑ‚Ğ¸Ğ½Ğ¸",
                        group="architecture_large_functions"
                    ))

    def _group_similar_issues(self):
        """Ğ“Ñ€ÑƒĞ¿ÑƒĞ²Ğ°Ñ‚Ğ¸ ÑÑ…Ğ¾Ğ¶Ñ– Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ¸ Ğ´Ğ»Ñ batch Ğ²Ğ¸Ñ€Ñ–ÑˆĞµĞ½Ğ½Ñ"""
        groups = defaultdict(list)

        for issue in self.issues:
            if issue.group:
                groups[issue.group].append(issue)

        # ĞĞ½Ğ¾Ğ²Ğ¸Ñ‚Ğ¸ Ğ¾Ğ¿Ğ¸ÑĞ¸ Ğ´Ğ»Ñ Ğ³Ñ€ÑƒĞ¿
        for group_name, group_issues in groups.items():
            if len(group_issues) > 1:
                for issue in group_issues:
                    issue.description = f"[Ğ“Ğ Ğ£ĞŸĞ: {len(group_issues)} ÑÑ…Ğ¾Ğ¶Ğ¸Ñ…] {issue.description}"

    async def _run_claude_analysis(self):
        """Ğ—Ğ°Ğ¿ÑƒÑÑ‚Ğ¸Ñ‚Ğ¸ Ñ–Ğ½Ñ‚ĞµĞ»ĞµĞºÑ‚ÑƒĞ°Ğ»ÑŒĞ½Ğ¸Ğ¹ Ğ°Ğ½Ğ°Ğ»Ñ–Ğ· Ñ‡ĞµÑ€ĞµĞ· Claude CLI"""
        if not self.claude_integration:
            logger.warning("Claude integration not available for intelligent analysis")
            return

        # Ğ’Ğ¸Ğ±Ñ€Ğ°Ñ‚Ğ¸ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ¸ Ğ´Ğ»Ñ Claude Ğ°Ğ½Ğ°Ğ»Ñ–Ğ·Ñƒ
        high_priority_issues = [
            issue for issue in self.issues
            if issue.severity in ["CRITICAL", "HIGH"]
        ][:self.analysis_config["max_claude_calls"]]

        logger.info("Running Claude analysis", issues_count=len(high_priority_issues))

        for issue in high_priority_issues:
            try:
                claude_analysis = await self._get_claude_analysis_for_issue(issue)
                issue.claude_analysis = claude_analysis
            except Exception as e:
                logger.error("Claude analysis failed for issue",
                           issue_description=issue.description, error=str(e))

    async def _get_claude_analysis_for_issue(self, issue: AuditIssue) -> str:
        """ĞÑ‚Ñ€Ğ¸Ğ¼Ğ°Ñ‚Ğ¸ Claude Ğ°Ğ½Ğ°Ğ»Ñ–Ğ· Ğ´Ğ»Ñ ĞºĞ¾Ğ½ĞºÑ€ĞµÑ‚Ğ½Ğ¾Ñ— Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ¸"""
        prompt = self._build_claude_prompt_for_issue(issue)

        try:
            response = await self.claude_integration.run_command(
                prompt=prompt,
                working_directory=self.project_root,
                user_id=0  # System user for audit
            )

            if response and response.content:
                return response.content.strip()
            else:
                return "Claude Ğ°Ğ½Ğ°Ğ»Ñ–Ğ· Ğ½ĞµĞ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ğ¸Ğ¹"

        except Exception as e:
            logger.error("Failed to get Claude analysis", error=str(e))
            return f"ĞŸĞ¾Ğ¼Ğ¸Ğ»ĞºĞ° Claude Ğ°Ğ½Ğ°Ğ»Ñ–Ğ·Ñƒ: {str(e)}"

    def _build_claude_prompt_for_issue(self, issue: AuditIssue) -> str:
        """ĞŸĞ¾Ğ±ÑƒĞ´ÑƒĞ²Ğ°Ñ‚Ğ¸ Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚ Ğ´Ğ»Ñ Claude Ğ°Ğ½Ğ°Ğ»Ñ–Ğ·Ñƒ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ¸"""

        # Ğ§Ğ¸Ñ‚Ğ°Ñ”Ğ¼Ğ¾ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚ Ğ½Ğ°Ğ²ĞºĞ¾Ğ»Ğ¾ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ¸
        context_lines = self._get_file_context(issue.file_path, issue.line_number)

        prompt = f"""
**ĞĞ£Ğ”Ğ˜Ğ¢ TELEGRAM Ğ‘ĞĞ¢Ğ - Ğ†ĞĞ¢Ğ•Ğ›Ğ•ĞšĞ¢Ğ£ĞĞ›Ğ¬ĞĞ˜Ğ™ ĞĞĞĞ›Ğ†Ğ— ĞŸĞ ĞĞ‘Ğ›Ğ•ĞœĞ˜**

**Ğ¢Ğ¸Ğ¿ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ¸:** {issue.category}
**Ğ¡ĞµÑ€Ğ¹Ğ¾Ğ·Ğ½Ñ–ÑÑ‚ÑŒ:** {issue.severity}
**ĞĞ¿Ğ¸Ñ:** {issue.description}
**Ğ¤Ğ°Ğ¹Ğ»:** {issue.file_path}:{issue.line_number}

**ĞšĞ¾Ğ´ Ğ½Ğ°Ğ²ĞºĞ¾Ğ»Ğ¾ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ¸:**
```python
{context_lines}
```

**ĞŸĞ¾Ñ‚Ğ¾Ñ‡Ğ½Ğ° Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ñ–Ñ:** {issue.fix_suggestion}

**Ğ—ĞĞ’Ğ”ĞĞĞĞ¯:**
1. ĞŸÑ€Ğ¾Ğ°Ğ½Ğ°Ğ»Ñ–Ğ·ÑƒĞ¹Ñ‚Ğµ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñƒ Ğ· Ñ‚Ğ¾Ñ‡ĞºĞ¸ Ğ·Ğ¾Ñ€Ñƒ Ğ°Ñ€Ñ…Ñ–Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ¸ Telegram Ğ±Ğ¾Ñ‚Ñ–Ğ²
2. ĞÑ†Ñ–Ğ½Ñ–Ñ‚ÑŒ Ğ¿Ğ¾Ñ‚ĞµĞ½Ñ†Ñ–Ğ¹Ğ½Ğ¸Ğ¹ Ğ²Ğ¿Ğ»Ğ¸Ğ² Ğ½Ğ° ĞºĞ¾Ñ€Ğ¸ÑÑ‚ÑƒĞ²Ğ°Ñ‡Ñ–Ğ²
3. Ğ—Ğ°Ğ¿Ñ€Ğ¾Ğ¿Ğ¾Ğ½ÑƒĞ¹Ñ‚Ğµ ĞºĞ¾Ğ½ĞºÑ€ĞµÑ‚Ğ½Ğµ Ñ€Ñ–ÑˆĞµĞ½Ğ½Ñ Ğ· ĞºĞ¾Ğ´Ğ¾Ğ¼
4. Ğ’Ğ¸Ğ·Ğ½Ğ°Ñ‡Ñ‚Ğµ Ñ‡Ğ¸ Ğ¼Ğ¾Ğ¶Ğµ Ñ†Ñ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ° Ğ¿Ñ€Ğ¸Ğ·Ğ²ĞµÑÑ‚Ğ¸ Ğ´Ğ¾ Ñ–Ğ½ÑˆĞ¸Ñ… Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼
5. ĞÑ†Ñ–Ğ½Ñ–Ñ‚Ğµ Ğ¿Ñ€Ñ–Ğ¾Ñ€Ğ¸Ñ‚ĞµÑ‚ Ğ²Ğ¸Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ½Ñ (1-10)

**ĞšĞĞĞ¢Ğ•ĞšĞ¡Ğ¢ ĞŸĞ ĞĞ•ĞšĞ¢Ğ£:**
- Ğ¦Ğµ Claude Code Telegram Bot Ğ· Ğ»Ğ¾ĞºĞ°Ğ»Ñ–Ğ·Ğ°Ñ†Ñ–Ñ”Ñ
- Ğ’Ğ¸ĞºĞ¾Ñ€Ğ¸ÑÑ‚Ğ¾Ğ²ÑƒÑ”Ñ‚ÑŒÑÑ python-telegram-bot Ğ±Ñ–Ğ±Ğ»Ñ–Ğ¾Ñ‚ĞµĞºĞ°
- Ğ„ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ° callback handlers Ñ‚Ğ° inline keyboards
- ĞŸÑ–Ğ´Ñ‚Ñ€Ğ¸Ğ¼ÑƒÑ”Ñ‚ÑŒÑÑ ÑƒĞºÑ€Ğ°Ñ—Ğ½ÑÑŒĞºĞ° Ñ‚Ğ° Ğ°Ğ½Ğ³Ğ»Ñ–Ğ¹ÑÑŒĞºĞ° Ğ¼Ğ¾Ğ²Ğ¸

Ğ”Ğ°Ğ¹Ñ‚Ğµ Ğ´ĞµÑ‚Ğ°Ğ»ÑŒĞ½Ğ¸Ğ¹ Ğ°Ğ½Ğ°Ğ»Ñ–Ğ· Ñ– Ğ¿Ñ€Ğ°ĞºÑ‚Ğ¸Ñ‡Ğ½Ñ– Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ñ–Ñ—.
"""
        return prompt

    def _get_file_context(self, file_path: str, line_number: int, context_size: int = 10) -> str:
        """ĞÑ‚Ñ€Ğ¸Ğ¼Ğ°Ñ‚Ğ¸ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚ Ğ½Ğ°Ğ²ĞºĞ¾Ğ»Ğ¾ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ½Ğ¾Ñ— Ğ»Ñ–Ğ½Ñ–Ñ—"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                lines = f.readlines()

            start = max(0, line_number - context_size - 1)
            end = min(len(lines), line_number + context_size)

            context_lines = []
            for i in range(start, end):
                prefix = ">>> " if i == line_number - 1 else "    "
                context_lines.append(f"{prefix}{i+1:3d}: {lines[i].rstrip()}")

            return "\n".join(context_lines)

        except Exception as e:
            return f"ĞĞµ Ğ²Ğ´Ğ°Ğ»Ğ¾ÑÑ Ğ¿Ñ€Ğ¾Ñ‡Ğ¸Ñ‚Ğ°Ñ‚Ğ¸ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚: {e}"

    async def _generate_recommendations(self) -> List[str]:
        """Ğ—Ğ³ĞµĞ½ĞµÑ€ÑƒĞ²Ğ°Ñ‚Ğ¸ Ğ·Ğ°Ğ³Ğ°Ğ»ÑŒĞ½Ñ– Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ñ–Ñ— Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ñ– Ğ·Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ¸Ñ… Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼"""
        recommendations = []

        # ĞĞ½Ğ°Ğ»Ñ–Ğ· Ğ¿Ğ°Ñ‚ĞµÑ€Ğ½Ñ–Ğ² Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼
        category_counts = defaultdict(int)
        severity_counts = defaultdict(int)

        for issue in self.issues:
            category_counts[issue.category] += 1
            severity_counts[issue.severity] += 1

        # Ğ ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ñ–Ñ— Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ñ– ĞºÑ€Ğ¸Ñ‚Ğ¸Ñ‡Ğ½Ğ¸Ñ… Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼
        if severity_counts["CRITICAL"] > 0:
            recommendations.append(f"ğŸš¨ ĞĞ•Ğ“ĞĞ™ĞĞ Ğ²Ğ¸Ğ¿Ñ€Ğ°Ğ²Ğ¸Ñ‚Ğ¸ {severity_counts['CRITICAL']} ĞºÑ€Ğ¸Ñ‚Ğ¸Ñ‡Ğ½Ğ¸Ñ… Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼")

        # Ğ ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ñ–Ñ— Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ñ– ĞºĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ñ–Ğ¹
        if category_counts["CALLBACK_ERROR"] > 3:
            recommendations.append("ğŸ”˜ ĞŸÑ€Ğ¾Ğ²ĞµÑÑ‚Ğ¸ Ñ€ĞµĞ²Ñ–Ğ·Ñ–Ñ Ğ²ÑÑ–Ñ… callback handlers - Ğ±Ğ°Ğ³Ğ°Ñ‚Ğ¾ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼")

        if category_counts["HARDCODED_UKRAINIAN"] > 5:
            recommendations.append("ğŸŒ Ğ—Ğ°Ğ²ĞµÑ€ÑˆĞ¸Ñ‚Ğ¸ Ğ¼Ñ–Ğ³Ñ€Ğ°Ñ†Ñ–Ñ Ğ½Ğ° Ğ»Ğ¾ĞºĞ°Ğ»Ñ–Ğ·Ğ°Ñ†Ñ–Ñ - Ğ·Ğ°Ğ±Ğ°Ğ³Ğ°Ñ‚Ğ¾ hardcoded Ñ‚ĞµĞºÑÑ‚Ñƒ")

        # Ğ—Ğ°Ğ³Ğ°Ğ»ÑŒĞ½Ñ– Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ñ–Ñ—
        if len(self.issues) > 20:
            recommendations.append("ğŸ“Š Ğ Ğ¾Ğ·Ğ³Ğ»ÑĞ½ÑƒÑ‚Ğ¸ Ğ²Ğ¿Ñ€Ğ¾Ğ²Ğ°Ğ´Ğ¶ĞµĞ½Ğ½Ñ CI/CD Ğ· Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡Ğ½Ğ¸Ğ¼Ğ¸ Ğ¿ĞµÑ€ĞµĞ²Ñ–Ñ€ĞºĞ°Ğ¼Ğ¸")

        return recommendations

    def _prepare_audit_result(self, recommendations: List[str]) -> AuditResult:
        """ĞŸÑ–Ğ´Ğ³Ğ¾Ñ‚ÑƒĞ²Ğ°Ñ‚Ğ¸ Ñ„Ñ–Ğ½Ğ°Ğ»ÑŒĞ½Ğ¸Ğ¹ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚ Ğ°ÑƒĞ´Ğ¸Ñ‚Ñƒ"""
        severity_counts = defaultdict(int)

        for issue in self.issues:
            severity_counts[issue.severity] += 1

        return AuditResult(
            total_issues=len(self.issues),
            critical_count=severity_counts["CRITICAL"],
            high_count=severity_counts["HIGH"],
            medium_count=severity_counts["MEDIUM"],
            low_count=severity_counts["LOW"],
            issues=sorted(self.issues, key=lambda x: (x.severity, x.category)),
            recommendations=recommendations
        )

    def _load_translation_keys(self):
        """Ğ—Ğ°Ğ²Ğ°Ğ½Ñ‚Ğ°Ğ¶Ğ¸Ñ‚Ğ¸ ĞºĞ»ÑÑ‡Ñ– Ğ¿ĞµÑ€ĞµĞºĞ»Ğ°Ğ´Ñ–Ğ² (ÑĞ¿Ñ€Ğ¾Ñ‰ĞµĞ½Ğ° Ğ²ĞµÑ€ÑÑ–Ñ Ğ· original script)"""
        translation_dir = self.project_root / "src" / "localization" / "translations"

        if not translation_dir.exists():
            return

        for lang_file in translation_dir.glob("*.json"):
            try:
                with open(lang_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)

                lang_code = lang_file.stem
                self.translation_keys[lang_code] = set()
                self._extract_translation_keys(data, "", self.translation_keys[lang_code])

            except Exception as e:
                logger.error("Failed to load translations", file=str(lang_file), error=str(e))

    def _extract_translation_keys(self, data: Union[dict, str], prefix: str, keys_set: Set[str]):
        """Ğ ĞµĞºÑƒÑ€ÑĞ¸Ğ²Ğ½Ğ¾ Ğ²Ğ¸Ñ‚ÑĞ³Ğ½ÑƒÑ‚Ğ¸ ĞºĞ»ÑÑ‡Ñ– Ğ¿ĞµÑ€ĞµĞºĞ»Ğ°Ğ´Ñ–Ğ²"""
        if isinstance(data, dict):
            for key, value in data.items():
                if key.startswith("_"):
                    continue
                new_prefix = f"{prefix}.{key}" if prefix else key
                self._extract_translation_keys(value, new_prefix, keys_set)
        else:
            keys_set.add(prefix)

    def _audit_callback_coverage(self):
        """ĞŸĞµÑ€ĞµĞ²Ñ–Ñ€Ğ¸Ñ‚Ğ¸ Ğ¿Ğ¾ĞºÑ€Ğ¸Ñ‚Ñ‚Ñ callback handlers"""
        # Ğ¡Ğ¿Ñ€Ğ¾Ñ‰ĞµĞ½Ğ° Ğ²ĞµÑ€ÑÑ–Ñ - Ñ‚ÑƒÑ‚ Ğ¼Ğ¾Ğ¶Ğ½Ğ° Ğ´Ğ¾Ğ´Ğ°Ñ‚Ğ¸ Ğ±Ñ–Ğ»ÑŒÑˆ ÑĞºĞ»Ğ°Ğ´Ğ½Ñƒ Ğ»Ğ¾Ğ³Ñ–ĞºÑƒ
        pass

    def _audit_translation_coverage(self):
        """ĞŸĞµÑ€ĞµĞ²Ñ–Ñ€Ğ¸Ñ‚Ğ¸ Ğ¿Ğ¾ĞºÑ€Ğ¸Ñ‚Ñ‚Ñ Ğ¿ĞµÑ€ĞµĞºĞ»Ğ°Ğ´Ñ–Ğ²"""
        if 'uk' in self.translation_keys and 'en' in self.translation_keys:
            uk_keys = self.translation_keys['uk']
            en_keys = self.translation_keys['en']

            # Ğ—Ğ½Ğ°Ğ¹Ñ‚Ğ¸ Ğ½ĞµÑĞ¿Ñ–Ğ²Ğ¿Ğ°Ğ´Ñ–Ğ½Ğ½Ñ
            missing_in_en = uk_keys - en_keys
            missing_in_uk = en_keys - uk_keys

            for key in missing_in_en:
                self.issues.append(AuditIssue(
                    category="MISSING_TRANSLATION",
                    severity="MEDIUM",
                    file_path="src/localization/translations/en.json",
                    line_number=0,
                    description=f"Ğ’Ñ–Ğ´ÑÑƒÑ‚Ğ½Ñ–Ğ¹ Ğ°Ğ½Ğ³Ğ»Ñ–Ğ¹ÑÑŒĞºĞ¸Ğ¹ Ğ¿ĞµÑ€ĞµĞºĞ»Ğ°Ğ´: {key}",
                    fix_suggestion=f"Ğ”Ğ¾Ğ´Ğ°Ñ‚Ğ¸ Ğ¿ĞµÑ€ĞµĞºĞ»Ğ°Ğ´ Ğ´Ğ»Ñ ĞºĞ»ÑÑ‡Ğ° '{key}'",
                    group="missing_translations_en"
                ))

    def _audit_architecture_issues(self):
        """ĞŸĞµÑ€ĞµĞ²Ñ–Ñ€Ğ¸Ñ‚Ğ¸ Ğ°Ñ€Ñ…Ñ–Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ½Ñ– Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ¸"""
        # Ğ¢ÑƒÑ‚ Ğ¼Ğ¾Ğ¶Ğ½Ğ° Ğ´Ğ¾Ğ´Ğ°Ñ‚Ğ¸ Ğ¿ĞµÑ€ĞµĞ²Ñ–Ñ€ĞºĞ¸ ÑĞ¿ĞµÑ†Ğ¸Ñ„Ñ–Ñ‡Ğ½Ñ– Ğ´Ğ»Ñ Ğ°Ñ€Ñ…Ñ–Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ¸ Ğ±Ğ¾Ñ‚Ñ–Ğ²
        pass

    def _check_translation_usage(self, tree: ast.AST, file_path: Path, lines: List[str]):
        """ĞŸĞµÑ€ĞµĞ²Ñ–Ñ€Ğ¸Ñ‚Ğ¸ Ğ²Ğ¸ĞºĞ¾Ñ€Ğ¸ÑÑ‚Ğ°Ğ½Ğ½Ñ Ğ¿ĞµÑ€ĞµĞºĞ»Ğ°Ğ´Ñ–Ğ² (ÑĞ¿Ñ€Ğ¾Ñ‰ĞµĞ½Ğ¾)"""
        pass

    def _check_hardcoded_strings(self, file_path: Path, lines: List[str]):
        """ĞŸĞµÑ€ĞµĞ²Ñ–Ñ€Ğ¸Ñ‚Ğ¸ hardcoded Ñ€ÑĞ´ĞºĞ¸ (ÑĞ¿Ñ€Ğ¾Ñ‰ĞµĞ½Ğ¾)"""
        pass

    def _check_button_callback_consistency(self, tree: ast.AST, file_path: Path, lines: List[str]):
        """ĞŸĞµÑ€ĞµĞ²Ñ–Ñ€Ğ¸Ñ‚Ğ¸ consistency ĞºĞ½Ğ¾Ğ¿Ğ¾Ğº Ñ‚Ğ° callbacks (ÑĞ¿Ñ€Ğ¾Ñ‰ĞµĞ½Ğ¾)"""
        pass

def format_audit_report(result: AuditResult) -> str:
    """Ğ¤Ğ¾Ñ€Ğ¼Ğ°Ñ‚ÑƒĞ²Ğ°Ñ‚Ğ¸ Ğ·Ğ²Ñ–Ñ‚ Ğ°ÑƒĞ´Ğ¸Ñ‚Ñƒ Ğ´Ğ»Ñ Telegram"""

    if result.total_issues == 0:
        return "ğŸ‰ **PERFECT CODE!** ĞŸÑ€Ğ¾Ğ±Ğ»ĞµĞ¼ Ğ½Ğµ Ğ·Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ¾ Ğ² ĞºĞ¾Ğ´Ñ– Ğ±Ğ¾Ñ‚Ğ°."

    report = []
    report.append(f"ğŸ” **Ğ†ĞĞ¢Ğ•Ğ›Ğ•ĞšĞ¢Ğ£ĞĞ›Ğ¬ĞĞ˜Ğ™ ĞĞ£Ğ”Ğ˜Ğ¢ Ğ‘ĞĞ¢Ğ**")
    report.append(f"ğŸ“Š **Ğ—Ğ°Ğ³Ğ°Ğ»Ğ¾Ğ¼ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼:** {result.total_issues}")
    report.append("")

    # Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ° ÑĞµÑ€Ğ¹Ğ¾Ğ·Ğ½Ğ¾ÑÑ‚Ñ–
    report.append("**Ğ Ğ¾Ğ·Ğ¿Ğ¾Ğ´Ñ–Ğ» Ğ·Ğ° ÑĞµÑ€Ğ¹Ğ¾Ğ·Ğ½Ñ–ÑÑ‚Ñ:**")
    if result.critical_count > 0:
        report.append(f"ğŸ”´ CRITICAL: {result.critical_count}")
    if result.high_count > 0:
        report.append(f"ğŸŸ  HIGH: {result.high_count}")
    if result.medium_count > 0:
        report.append(f"ğŸŸ¡ MEDIUM: {result.medium_count}")
    if result.low_count > 0:
        report.append(f"ğŸŸ¢ LOW: {result.low_count}")
    report.append("")

    # Ğ¢Ğ¾Ğ¿ ĞºÑ€Ğ¸Ñ‚Ğ¸Ñ‡Ğ½Ñ– Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ğ¸
    critical_issues = [i for i in result.issues if i.severity == "CRITICAL"][:5]
    if critical_issues:
        report.append("ğŸš¨ **ĞšĞ Ğ˜Ğ¢Ğ˜Ğ§ĞĞ† ĞŸĞ ĞĞ‘Ğ›Ğ•ĞœĞ˜:**")
        for i, issue in enumerate(critical_issues, 1):
            report.append(f"{i}. {issue.description}")
            report.append(f"   ğŸ“ `{issue.file_path}:{issue.line_number}`")
            if issue.claude_analysis:
                report.append(f"   ğŸ¤– Claude: {issue.claude_analysis[:100]}...")
        report.append("")

    # Ğ ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ñ–Ñ—
    if result.recommendations:
        report.append("ğŸ’¡ **Ğ Ğ•ĞšĞĞœĞ•ĞĞ”ĞĞ¦Ğ†Ğ‡:**")
        for rec in result.recommendations:
            report.append(f"â€¢ {rec}")
        report.append("")

    # Claude Ğ·Ğ°Ğ³Ğ°Ğ»ÑŒĞ½Ğ¸Ğ¹ Ğ°Ğ½Ğ°Ğ»Ñ–Ğ·
    if result.claude_summary:
        report.append(f"ğŸ§  **CLAUDE ĞĞĞĞ›Ğ†Ğ—:**\n{result.claude_summary[:500]}...")

    return "\n".join(report)