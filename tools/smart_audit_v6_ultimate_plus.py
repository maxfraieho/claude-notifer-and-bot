#!/usr/bin/env python3
"""
ULTIMATE PLUS AUDITOR v6 - –†–æ–∑—à–∏—Ä–µ–Ω–∏–π –∞–Ω–∞–ª—ñ–∑–∞—Ç–æ—Ä –¥–ª—è –≤–∏—è–≤–ª–µ–Ω–Ω—è –ø—Ä–æ–±–ª–µ–º –∑ –∫–Ω–æ–ø–∫–∞–º–∏, –ø–µ—Ä–µ–∫–ª–∞–¥–∞–º–∏ —Ç–∞ –ª–æ–≥—ñ–∫–æ—é
–í–∏—è–≤–ª—è—î —Å–ø–µ—Ü–∏—Ñ—ñ—á–Ω—ñ –ø—Ä–æ–±–ª–µ–º–∏ –∑ –ª–æ–∫–∞–ª—ñ–∑–∞—Ü—ñ—î—é, callback handlers —Ç–∞ UI consistency
"""

import ast
import json
import os
import re
import sys
from pathlib import Path
from typing import Dict, List, Set, Tuple, Union
from dataclasses import dataclass
from collections import defaultdict

@dataclass
class Issue:
    category: str
    severity: str
    file_path: str
    line_number: int
    description: str
    code_snippet: str = ""
    fix_suggestion: str = ""

class UltimatePlusAuditor:
    def __init__(self, project_root: str):
        self.project_root = Path(project_root)
        self.issues: List[Issue] = []
        self.translation_keys: Dict[str, Set[str]] = {}
        self.callback_handlers: Set[str] = set()
        self.button_callbacks: Set[str] = set()
        self.used_translation_keys: Set[str] = set()
        self.undefined_translation_keys: Set[str] = set()
        
    def audit(self) -> List[Issue]:
        """–í–∏–∫–æ–Ω–∞—Ç–∏ –ø–æ–≤–Ω–∏–π –∞—É–¥–∏—Ç –ø—Ä–æ–µ–∫—Ç—É"""
        print("üîç –ó–∞–ø—É—Å–∫ Ultimate Plus Audit v6...")
        
        # –ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –ø–µ—Ä–µ–∫–ª–∞–¥–∏
        self._load_translation_keys()
        
        # –ó–Ω–∞–π—Ç–∏ –≤—Å—ñ Python —Ñ–∞–π–ª–∏
        python_files = list(self.project_root.rglob("*.py"))
        
        for file_path in python_files:
            if "venv" in str(file_path) or "__pycache__" in str(file_path):
                continue
                
            try:
                self._audit_python_file(file_path)
            except Exception as e:
                self.issues.append(Issue(
                    category="PARSING_ERROR",
                    severity="HIGH",
                    file_path=str(file_path),
                    line_number=0,
                    description=f"–ü–æ–º–∏–ª–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥—É —Ñ–∞–π–ª—É: {e}"
                ))
        
        # –°–ø–µ—Ü—ñ–∞–ª—å–Ω—ñ –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏
        self._audit_callback_coverage()
        self._audit_translation_coverage()
        self._audit_button_consistency()
        self._audit_hardcoded_strings()
        
        return sorted(self.issues, key=lambda x: (x.severity, x.category))
    
    def _load_translation_keys(self):
        """–ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –∫–ª—é—á—ñ –ø–µ—Ä–µ–∫–ª–∞–¥—ñ–≤ –∑ JSON —Ñ–∞–π–ª—ñ–≤"""
        translation_dir = self.project_root / "src" / "localization" / "translations"
        
        for lang_file in translation_dir.glob("*.json"):
            try:
                with open(lang_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    
                lang_code = lang_file.stem
                self.translation_keys[lang_code] = set()
                self._extract_translation_keys(data, "", self.translation_keys[lang_code])
                
            except Exception as e:
                self.issues.append(Issue(
                    category="TRANSLATION_ERROR",
                    severity="HIGH",
                    file_path=str(lang_file),
                    line_number=0,
                    description=f"–ü–æ–º–∏–ª–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –ø–µ—Ä–µ–∫–ª–∞–¥—ñ–≤: {e}"
                ))
    
    def _extract_translation_keys(self, data: Union[dict, str], prefix: str, keys_set: Set[str]):
        """–†–µ–∫—É—Ä—Å–∏–≤–Ω–æ –≤–∏—Ç—è–≥–Ω—É—Ç–∏ –∫–ª—é—á—ñ –ø–µ—Ä–µ–∫–ª–∞–¥—ñ–≤"""
        if isinstance(data, dict):
            for key, value in data.items():
                if key.startswith("_"):  # –ü—Ä–æ–ø—É—Å—Ç–∏—Ç–∏ –º–µ—Ç–∞-–∫–ª—é—á—ñ
                    continue
                new_prefix = f"{prefix}.{key}" if prefix else key
                self._extract_translation_keys(value, new_prefix, keys_set)
        else:
            keys_set.add(prefix)
    
    def _audit_python_file(self, file_path: Path):
        """–ê—É–¥–∏—Ç –æ–¥–Ω–æ–≥–æ Python —Ñ–∞–π–ª—É"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
                lines = content.split('\n')
            
            tree = ast.parse(content)
            
            # –†—ñ–∑–Ω—ñ —Ç–∏–ø–∏ –∞–Ω–∞–ª—ñ–∑—É
            self._check_callback_handlers(tree, file_path, lines)
            self._check_button_definitions(tree, file_path, lines)
            self._check_translation_usage(tree, file_path, lines)
            self._check_hardcoded_ukrainian(file_path, lines)
            self._check_hardcoded_english(file_path, lines)
            self._check_string_concatenation(tree, file_path, lines)
            self._check_missing_error_handling(tree, file_path, lines)
            self._check_button_callback_consistency(tree, file_path, lines)
            
        except Exception as e:
            self.issues.append(Issue(
                category="FILE_ERROR",
                severity="MEDIUM",
                file_path=str(file_path),
                line_number=0,
                description=f"–ü–æ–º–∏–ª–∫–∞ –æ–±—Ä–æ–±–∫–∏ —Ñ–∞–π–ª—É: {e}"
            ))
    
    def _check_callback_handlers(self, tree: ast.AST, file_path: Path, lines: List[str]):
        """–ü–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ callback handlers"""
        for node in ast.walk(tree):
            if isinstance(node, ast.FunctionDef) and node.name.endswith('_callback'):
                self.callback_handlers.add(node.name)
            
            # –ü–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ CallbackQueryHandler
            if isinstance(node, ast.Call):
                if (isinstance(node.func, ast.Name) and 
                    node.func.id == 'CallbackQueryHandler'):
                    
                    if len(node.args) == 0:
                        self.issues.append(Issue(
                            category="CALLBACK_ERROR",
                            severity="HIGH",
                            file_path=str(file_path),
                            line_number=getattr(node, 'lineno', 0),
                            description="CallbackQueryHandler –±–µ–∑ handler —Ñ—É–Ω–∫—Ü—ñ—ó",
                            code_snippet=lines[getattr(node, 'lineno', 1) - 1] if lines else "",
                            fix_suggestion="–î–æ–¥–∞–π—Ç–µ handler —Ñ—É–Ω–∫—Ü—ñ—é –≤ CallbackQueryHandler"
                        ))
    
    def _check_button_definitions(self, tree: ast.AST, file_path: Path, lines: List[str]):
        """–ü–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ –≤–∏–∑–Ω–∞—á–µ–Ω–Ω—è –∫–Ω–æ–ø–æ–∫"""
        for node in ast.walk(tree):
            if isinstance(node, ast.Call):
                # InlineKeyboardButton
                if (isinstance(node.func, ast.Name) and 
                    node.func.id == 'InlineKeyboardButton'):
                    
                    callback_data = None
                    button_text = None
                    
                    # –ó–Ω–∞–π—Ç–∏ callback_data
                    for keyword in node.keywords:
                        if keyword.arg == 'callback_data':
                            if isinstance(keyword.value, ast.Constant):
                                callback_data = keyword.value.value
                                self.button_callbacks.add(callback_data)
                    
                    # –ó–Ω–∞–π—Ç–∏ text –∫–Ω–æ–ø–∫–∏
                    if node.args:
                        if isinstance(node.args[0], ast.Constant):
                            button_text = node.args[0].value
                        elif isinstance(node.args[0], ast.Call):
                            # –ü–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ —á–∏ —Ü–µ –≤–∏–∫–ª–∏–∫ —Ñ—É–Ω–∫—Ü—ñ—ó t()
                            if not self._is_translation_call(node.args[0]):
                                self.issues.append(Issue(
                                    category="BUTTON_TEXT_ERROR",
                                    severity="MEDIUM",
                                    file_path=str(file_path),
                                    line_number=getattr(node, 'lineno', 0),
                                    description="–¢–µ–∫—Å—Ç –∫–Ω–æ–ø–∫–∏ –Ω–µ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î –ª–æ–∫–∞–ª—ñ–∑–∞—Ü—ñ—é",
                                    code_snippet=lines[getattr(node, 'lineno', 1) - 1] if lines else "",
                                    fix_suggestion="–í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π—Ç–µ await t(context, user_id, 'key') –¥–ª—è —Ç–µ–∫—Å—Ç—É –∫–Ω–æ–ø–∫–∏"
                                ))
                    
                    # –ü–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ —á–∏ —î hardcoded text
                    if button_text and isinstance(button_text, str):
                        if self._is_ukrainian_text(button_text) or self._is_english_text(button_text):
                            self.issues.append(Issue(
                                category="HARDCODED_BUTTON_TEXT",
                                severity="HIGH",
                                file_path=str(file_path),
                                line_number=getattr(node, 'lineno', 0),
                                description=f"Hardcoded —Ç–µ–∫—Å—Ç –∫–Ω–æ–ø–∫–∏: '{button_text}'",
                                code_snippet=lines[getattr(node, 'lineno', 1) - 1] if lines else "",
                                fix_suggestion=f"–ó–∞–º—ñ–Ω–∏—Ç–∏ –Ω–∞ await t(context, user_id, 'buttons.{self._suggest_key(button_text)}')"
                            ))
    
    def _check_translation_usage(self, tree: ast.AST, file_path: Path, lines: List[str]):
        """–ü–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è —Ñ—É–Ω–∫—Ü—ñ—ó t()"""
        for node in ast.walk(tree):
            if isinstance(node, ast.Call):
                if self._is_translation_call(node):
                    # –í–∏—Ç—è–≥–Ω—É—Ç–∏ –∫–ª—é—á –ø–µ—Ä–µ–∫–ª–∞–¥—É
                    if len(node.args) >= 3 and isinstance(node.args[2], ast.Constant):
                        translation_key = node.args[2].value
                        self.used_translation_keys.add(translation_key)
                        
                        # –ü–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ —á–∏ —ñ—Å–Ω—É—î –∫–ª—é—á –≤ –ø–µ—Ä–µ–∫–ª–∞–¥–∞—Ö
                        key_exists = False
                        for lang_keys in self.translation_keys.values():
                            if translation_key in lang_keys:
                                key_exists = True
                                break
                        
                        if not key_exists:
                            self.undefined_translation_keys.add(translation_key)
                            self.issues.append(Issue(
                                category="UNDEFINED_TRANSLATION_KEY",
                                severity="HIGH",
                                file_path=str(file_path),
                                line_number=getattr(node, 'lineno', 0),
                                description=f"–ù–µ–≤–∏–∑–Ω–∞—á–µ–Ω–∏–π –∫–ª—é—á –ø–µ—Ä–µ–∫–ª–∞–¥—É: '{translation_key}'",
                                code_snippet=lines[getattr(node, 'lineno', 1) - 1] if lines else "",
                                fix_suggestion=f"–î–æ–¥–∞–π—Ç–µ –∫–ª—é—á '{translation_key}' –≤ —Ñ–∞–π–ª–∏ –ø–µ—Ä–µ–∫–ª–∞–¥—ñ–≤"
                            ))
    
    def _check_hardcoded_ukrainian(self, file_path: Path, lines: List[str]):
        """–ü–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ hardcoded —É–∫—Ä–∞—ó–Ω—Å—å–∫—ñ —Ä—è–¥–∫–∏"""
        ukrainian_patterns = [
            r'["\'].*[–∞-—è—î—ñ—ó“ë].*["\']',  # –ú—ñ—Å—Ç–∏—Ç—å —É–∫—Ä–∞—ó–Ω—Å—å–∫—ñ –ª—ñ—Ç–µ—Ä–∏
            r'["\'].*(–ø–æ–º–∏–ª–∫–∞|–æ—à–∏–±–∫–∞|error).*["\']',  # –°–ª–æ–≤–∞ –ø–æ–º–∏–ª–∫–∏
            r'["\'].*(–∫–æ–º–∞–Ω–¥–∞|–∫–Ω–æ–ø–∫–∞|–º–µ–Ω—é|–Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è).*["\']',  # UI —Ç–µ—Ä–º—ñ–Ω–æ–ª–æ–≥—ñ—è
        ]
        
        for i, line in enumerate(lines, 1):
            for pattern in ukrainian_patterns:
                matches = re.finditer(pattern, line, re.IGNORECASE)
                for match in matches:
                    # –ü—Ä–æ–ø—É—Å—Ç–∏—Ç–∏ –∫–æ–º–µ–Ω—Ç–∞—Ä—ñ —Ç–∞ docstrings
                    if line.strip().startswith('#') or '"""' in line or "'''" in line:
                        continue
                        
                    # –ü—Ä–æ–ø—É—Å—Ç–∏—Ç–∏ —è–∫—â–æ –≤–∂–µ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î t()
                    if 'await t(' in line or 't(' in line:
                        continue
                    
                    matched_text = match.group()
                    self.issues.append(Issue(
                        category="HARDCODED_UKRAINIAN",
                        severity="HIGH",
                        file_path=str(file_path),
                        line_number=i,
                        description=f"Hardcoded —É–∫—Ä–∞—ó–Ω—Å—å–∫—ñ–π —Ç–µ–∫—Å—Ç: {matched_text}",
                        code_snippet=line.strip(),
                        fix_suggestion=f"–ó–∞–º—ñ–Ω–∏—Ç–∏ –Ω–∞ await t(context, user_id, 'appropriate.key')"
                    ))
    
    def _check_hardcoded_english(self, file_path: Path, lines: List[str]):
        """–ü–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ hardcoded –∞–Ω–≥–ª—ñ–π—Å—å–∫—ñ —Ä—è–¥–∫–∏ –≤ UI"""
        english_ui_patterns = [
            r'["\'].*\b(error|failed|success|loading|processing|completed)\b.*["\']',
            r'["\'].*\b(button|menu|settings|help|status|export)\b.*["\']',
            r'["\'].*(‚ùå|‚úÖ|üîÑ|üìä|‚öôÔ∏è|üìÅ|üÜï).*["\']',  # –ó –µ–º–æ–¥–∑—ñ
        ]
        
        for i, line in enumerate(lines, 1):
            for pattern in english_ui_patterns:
                matches = re.finditer(pattern, line, re.IGNORECASE)
                for match in matches:
                    if line.strip().startswith('#') or '"""' in line:
                        continue
                    if 'await t(' in line or 't(' in line:
                        continue
                        
                    matched_text = match.group()
                    self.issues.append(Issue(
                        category="HARDCODED_ENGLISH",
                        severity="MEDIUM",
                        file_path=str(file_path),
                        line_number=i,
                        description=f"Hardcoded –∞–Ω–≥–ª—ñ–π—Å—å–∫–∏–π UI —Ç–µ–∫—Å—Ç: {matched_text}",
                        code_snippet=line.strip(),
                        fix_suggestion="–í–∏–∫–æ—Ä–∏—Å—Ç–∞—Ç–∏ –ª–æ–∫–∞–ª—ñ–∑–∞—Ü—ñ—é –∑–∞–º—ñ—Å—Ç—å hardcoded —Ç–µ–∫—Å—Ç—É"
                    ))
    
    def _check_string_concatenation(self, tree: ast.AST, file_path: Path, lines: List[str]):
        """–ü–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ –∫–æ–Ω–∫–∞—Ç–µ–Ω–∞—Ü—ñ—é —Ä—è–¥–∫—ñ–≤ –∑–∞–º—ñ—Å—Ç—å —Ñ–æ—Ä–º–∞—Ç—É–≤–∞–Ω–Ω—è"""
        for node in ast.walk(tree):
            if isinstance(node, ast.BinOp) and isinstance(node.op, ast.Add):
                if (isinstance(node.left, ast.Constant) and isinstance(node.left.value, str) and
                    isinstance(node.right, ast.Constant) and isinstance(node.right.value, str)):
                    
                    self.issues.append(Issue(
                        category="STRING_CONCATENATION",
                        severity="LOW",
                        file_path=str(file_path),
                        line_number=getattr(node, 'lineno', 0),
                        description="–ö–æ–Ω–∫–∞—Ç–µ–Ω–∞—Ü—ñ—è —Ä—è–¥–∫—ñ–≤ –∑–∞–º—ñ—Å—Ç—å f-strings",
                        code_snippet=lines[getattr(node, 'lineno', 1) - 1] if lines else "",
                        fix_suggestion="–í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π—Ç–µ f-strings –∞–±–æ .format()"
                    ))
    
    def _check_missing_error_handling(self, tree: ast.AST, file_path: Path, lines: List[str]):
        """–ü–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ –≤—ñ–¥—Å—É—Ç–Ω—ñ—Å—Ç—å –æ–±—Ä–æ–±–∫–∏ –ø–æ–º–∏–ª–æ–∫"""
        for node in ast.walk(tree):
            if isinstance(node, ast.ExceptHandler):
                if node.type is None:  # except: –±–µ–∑ —Ç–∏–ø—É
                    # –ü–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ —á–∏ —î pass –∞–±–æ –ø—Ä–æ—Å—Ç–æ –ª–æ–≥—É–≤–∞–Ω–Ω—è
                    if (len(node.body) == 1 and 
                        isinstance(node.body[0], ast.Pass)):
                        
                        self.issues.append(Issue(
                            category="SILENT_FAILURE",
                            severity="CRITICAL",
                            file_path=str(file_path),
                            line_number=getattr(node, 'lineno', 0),
                            description="Silent failure - except: pass",
                            code_snippet=lines[getattr(node, 'lineno', 1) - 1] if lines else "",
                            fix_suggestion="–í–∏–∫–æ—Ä–∏—Å—Ç–∞—Ç–∏ safe_user_error() –∞–±–æ proper error handling"
                        ))
    
    def _check_button_callback_consistency(self, tree: ast.AST, file_path: Path, lines: List[str]):
        """–ü–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ consistency –º—ñ–∂ –∫–Ω–æ–ø–∫–∞–º–∏ —Ç–∞ callback handlers"""
        # –ó–Ω–∞–π—Ç–∏ –≤—Å—ñ callback_data —É –∫–Ω–æ–ø–∫–∞—Ö
        button_callbacks_in_file = set()
        
        for node in ast.walk(tree):
            if isinstance(node, ast.Call):
                if (isinstance(node.func, ast.Name) and 
                    node.func.id == 'InlineKeyboardButton'):
                    
                    for keyword in node.keywords:
                        if keyword.arg == 'callback_data':
                            if isinstance(keyword.value, ast.Constant):
                                button_callbacks_in_file.add(keyword.value.value)
        
        # –ó–Ω–∞–π—Ç–∏ –≤—Å—ñ pattern —É CallbackQueryHandler
        handler_patterns = set()
        
        for node in ast.walk(tree):
            if isinstance(node, ast.Call):
                if (isinstance(node.func, ast.Name) and 
                    node.func.id == 'CallbackQueryHandler'):
                    
                    for keyword in node.keywords:
                        if keyword.arg == 'pattern':
                            if isinstance(keyword.value, ast.Constant):
                                handler_patterns.add(keyword.value.value)
        
        # –ü–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ –Ω–µ—Å–ø—ñ–≤–ø–∞–¥—ñ–Ω–Ω—è
        for callback in button_callbacks_in_file:
            if not any(re.match(pattern, callback) for pattern in handler_patterns):
                self.issues.append(Issue(
                    category="MISSING_CALLBACK_HANDLER",
                    severity="HIGH",
                    file_path=str(file_path),
                    line_number=0,
                    description=f"–í—ñ–¥—Å—É—Ç–Ω—ñ–π handler –¥–ª—è callback: '{callback}'",
                    fix_suggestion=f"–î–æ–¥–∞—Ç–∏ CallbackQueryHandler –∑ pattern –¥–ª—è '{callback}'"
                ))
    
    def _audit_callback_coverage(self):
        """–ü–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ –ø–æ–∫—Ä–∏—Ç—Ç—è callback handlers"""
        uncovered_callbacks = self.button_callbacks - {
            cb for cb in self.button_callbacks 
            if any(cb.startswith(prefix) for prefix in ['action:', 'schedule:', 'git:', 'export:'])
        }
        
        for callback in uncovered_callbacks:
            self.issues.append(Issue(
                category="UNCOVERED_CALLBACK",
                severity="HIGH",
                file_path="GLOBAL",
                line_number=0,
                description=f"Callback –±–µ–∑ handler: '{callback}'",
                fix_suggestion=f"–î–æ–¥–∞—Ç–∏ handler –¥–ª—è callback '{callback}'"
            ))
    
    def _audit_translation_coverage(self):
        """–ü–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ –ø–æ–∫—Ä–∏—Ç—Ç—è –ø–µ—Ä–µ–∫–ª–∞–¥—ñ–≤"""
        if 'uk' in self.translation_keys and 'en' in self.translation_keys:
            uk_keys = self.translation_keys['uk']
            en_keys = self.translation_keys['en']
            
            # –ö–ª—é—á—ñ —Ç—ñ–ª—å–∫–∏ –≤ —É–∫—Ä–∞—ó–Ω—Å—å–∫—ñ–π
            uk_only = uk_keys - en_keys
            for key in uk_only:
                self.issues.append(Issue(
                    category="MISSING_ENGLISH_TRANSLATION",
                    severity="MEDIUM",
                    file_path="src/localization/translations/en.json",
                    line_number=0,
                    description=f"–í—ñ–¥—Å—É—Ç–Ω—ñ–π –∞–Ω–≥–ª—ñ–π—Å—å–∫–∏–π –ø–µ—Ä–µ–∫–ª–∞–¥ –¥–ª—è –∫–ª—é—á–∞: '{key}'",
                    fix_suggestion=f"–î–æ–¥–∞—Ç–∏ –ø–µ—Ä–µ–∫–ª–∞–¥ –¥–ª—è '{key}' –≤ en.json"
                ))
            
            # –ö–ª—é—á—ñ —Ç—ñ–ª—å–∫–∏ –≤ –∞–Ω–≥–ª—ñ–π—Å—å–∫—ñ–π
            en_only = en_keys - uk_keys
            for key in en_only:
                self.issues.append(Issue(
                    category="MISSING_UKRAINIAN_TRANSLATION",
                    severity="MEDIUM",
                    file_path="src/localization/translations/uk.json",
                    line_number=0,
                    description=f"–í—ñ–¥—Å—É—Ç–Ω—ñ–π —É–∫—Ä–∞—ó–Ω—Å—å–∫–∏–π –ø–µ—Ä–µ–∫–ª–∞–¥ –¥–ª—è –∫–ª—é—á–∞: '{key}'",
                    fix_suggestion=f"–î–æ–¥–∞—Ç–∏ –ø–µ—Ä–µ–∫–ª–∞–¥ –¥–ª—è '{key}' –≤ uk.json"
                ))
    
    def _audit_button_consistency(self):
        """–ü–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ consistency –∫–Ω–æ–ø–æ–∫"""
        # –ü–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ —á–∏ –≤—Å—ñ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω—ñ –∫–ª—é—á—ñ —ñ—Å–Ω—É—é—Ç—å
        for key in self.undefined_translation_keys:
            if key.startswith('buttons.'):
                self.issues.append(Issue(
                    category="BUTTON_TRANSLATION_MISSING",
                    severity="HIGH",
                    file_path="GLOBAL",
                    line_number=0,
                    description=f"–í—ñ–¥—Å—É—Ç–Ω—ñ–π –ø–µ—Ä–µ–∫–ª–∞–¥ –¥–ª—è –∫–Ω–æ–ø–∫–∏: '{key}'",
                    fix_suggestion=f"–î–æ–¥–∞—Ç–∏ –ø–µ—Ä–µ–∫–ª–∞–¥ '{key}' –≤ —Ñ–∞–π–ª–∏ –ª–æ–∫–∞–ª—ñ–∑–∞—Ü—ñ—ó"
                ))
    
    def _audit_hardcoded_strings(self):
        """–ó–∞–≥–∞–ª—å–Ω–∞ –ø–µ—Ä–µ–≤—ñ—Ä–∫–∞ hardcoded —Ä—è–¥–∫—ñ–≤"""
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        hardcoded_count = len([i for i in self.issues if 'HARDCODED' in i.category])
        if hardcoded_count > 0:
            self.issues.append(Issue(
                category="HARDCODED_SUMMARY",
                severity="HIGH",
                file_path="GLOBAL",
                line_number=0,
                description=f"–ó–Ω–∞–π–¥–µ–Ω–æ {hardcoded_count} hardcoded —Ä—è–¥–∫—ñ–≤",
                fix_suggestion="–ó–∞–º—ñ–Ω–∏—Ç–∏ –≤—Å—ñ hardcoded —Ä—è–¥–∫–∏ –Ω–∞ –ª–æ–∫–∞–ª—ñ–∑–∞—Ü—ñ—é"
            ))
    
    def _is_translation_call(self, node: ast.Call) -> bool:
        """–ü–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ —á–∏ —Ü–µ –≤–∏–∫–ª–∏–∫ —Ñ—É–Ω–∫—Ü—ñ—ó t()"""
        return (isinstance(node.func, ast.Name) and node.func.id == 't') or \
               (isinstance(node.func, ast.Attribute) and node.func.attr == 't')
    
    def _is_ukrainian_text(self, text: str) -> bool:
        """–ü–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ —á–∏ –º—ñ—Å—Ç–∏—Ç—å —Ç–µ–∫—Å—Ç —É–∫—Ä–∞—ó–Ω—Å—å–∫—ñ –ª—ñ—Ç–µ—Ä–∏"""
        return bool(re.search(r'[–∞-—è—î—ñ—ó“ë]', text, re.IGNORECASE))
    
    def _is_english_text(self, text: str) -> bool:
        """–ü–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ —á–∏ —Ü–µ –∞–Ω–≥–ª—ñ–π—Å—å–∫–∏–π UI —Ç–µ–∫—Å—Ç"""
        ui_words = ['error', 'failed', 'success', 'loading', 'button', 'menu', 'settings']
        return any(word in text.lower() for word in ui_words)
    
    def _suggest_key(self, text: str) -> str:
        """–ó–∞–ø—Ä–æ–ø–æ–Ω—É–≤–∞—Ç–∏ –∫–ª—é—á –¥–ª—è —Ç–µ–∫—Å—Ç—É"""
        # –ü—Ä–æ—Å—Ç–∏–π –∞–ª–≥–æ—Ä–∏—Ç–º –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó –∫–ª—é—á–∞
        text = re.sub(r'[^\w\s]', '', text.lower())
        text = re.sub(r'\s+', '_', text.strip())
        return text[:30]  # –û–±–º–µ–∂–∏—Ç–∏ –¥–æ–≤–∂–∏–Ω—É

def generate_report(issues: List[Issue]) -> str:
    """–ó–≥–µ–Ω–µ—Ä—É–≤–∞—Ç–∏ –∑–≤—ñ—Ç —É markdown —Ñ–æ—Ä–º–∞—Ç—ñ"""
    if not issues:
        return "üéâ **PERFECT CODE!** –ü—Ä–æ–±–ª–µ–º –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ."
    
    # –ì—Ä—É–ø—É–≤–∞–Ω–Ω—è –∑–∞ –∫–∞—Ç–µ–≥–æ—Ä—ñ—è–º–∏
    by_category = defaultdict(list)
    by_severity = defaultdict(int)
    
    for issue in issues:
        by_category[issue.category].append(issue)
        by_severity[issue.severity] += 1
    
    report = []
    report.append("# üîç ULTIMATE PLUS AUDIT REPORT v6")
    report.append(f"**–î–∞—Ç–∞:** {os.popen('date').read().strip()}")
    report.append("")
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    report.append("## üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê")
    report.append(f"- üî¥ **CRITICAL:** {by_severity['CRITICAL']}")
    report.append(f"- üü† **HIGH:** {by_severity['HIGH']}")
    report.append(f"- üü° **MEDIUM:** {by_severity['MEDIUM']}")
    report.append(f"- üü¢ **LOW:** {by_severity['LOW']}")
    report.append(f"- **–ó–ê–ì–ê–õ–û–ú:** {len(issues)}")
    report.append("")
    
    # –¢–æ–ø –ø—Ä–æ–±–ª–µ–º–∏
    report.append("## üö® –ö–†–ò–¢–ò–ß–ù–Ü –ü–†–û–ë–õ–ï–ú–ò")
    critical_issues = [i for i in issues if i.severity == 'CRITICAL']
    if critical_issues:
        for i, issue in enumerate(critical_issues[:10], 1):
            report.append(f"### {i}. {issue.description}")
            report.append(f"**–§–∞–π–ª:** `{issue.file_path}:{issue.line_number}`")
            if issue.code_snippet:
                report.append(f"**–ö–æ–¥:** `{issue.code_snippet}`")
            if issue.fix_suggestion:
                report.append(f"**–í–∏–ø—Ä–∞–≤–ª–µ–Ω–Ω—è:** {issue.fix_suggestion}")
            report.append("")
    else:
        report.append("‚úÖ –ö—Ä–∏—Ç–∏—á–Ω–∏—Ö –ø—Ä–æ–±–ª–µ–º –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ!")
        report.append("")
    
    # –ü—Ä–æ–±–ª–µ–º–∏ –∑ –∫–Ω–æ–ø–∫–∞–º–∏
    button_issues = [i for i in issues if 'BUTTON' in i.category or 'CALLBACK' in i.category]
    if button_issues:
        report.append("## üîò –ü–†–û–ë–õ–ï–ú–ò –ó –ö–ù–û–ü–ö–ê–ú–ò –¢–ê CALLBACKS")
        for issue in button_issues[:15]:
            report.append(f"- **{issue.severity}:** {issue.description} (`{issue.file_path}:{issue.line_number}`)")
        report.append("")
    
    # –ü—Ä–æ–±–ª–µ–º–∏ –∑ –ª–æ–∫–∞–ª—ñ–∑–∞—Ü—ñ—î—é
    localization_issues = [i for i in issues if 'TRANSLATION' in i.category or 'HARDCODED' in i.category]
    if localization_issues:
        report.append("## üåê –ü–†–û–ë–õ–ï–ú–ò –ó –õ–û–ö–ê–õ–Ü–ó–ê–¶–Ü–Ñ–Æ")
        for issue in localization_issues[:20]:
            report.append(f"- **{issue.severity}:** {issue.description} (`{issue.file_path}:{issue.line_number}`)")
        report.append("")
    
    # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó
    report.append("## üí° –ü–†–Ü–û–†–ò–¢–ï–¢–ù–Ü –î–Ü–á")
    report.append("1. **–í–∏–ø—Ä–∞–≤–∏—Ç–∏ –≤—Å—ñ CRITICAL –ø—Ä–æ–±–ª–µ–º–∏** - –≤–æ–Ω–∏ –±–ª–æ–∫—É—é—Ç—å —Ñ—É–Ω–∫—Ü—ñ–æ–Ω–∞–ª—å–Ω—ñ—Å—Ç—å")
    report.append("2. **–î–æ–¥–∞—Ç–∏ –≤—ñ–¥—Å—É—Ç–Ω—ñ callback handlers** - –∫–Ω–æ–ø–∫–∏ –Ω–µ –ø—Ä–∞—Ü—é—é—Ç—å")
    report.append("3. **–ó–∞–≤–µ—Ä—à–∏—Ç–∏ –ª–æ–∫–∞–ª—ñ–∑–∞—Ü—ñ—é** - –∑–∞–º—ñ–Ω–∏—Ç–∏ hardcoded —Ç–µ–∫—Å—Ç–∏")
    report.append("4. **–ü–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏ consistency –ø–µ—Ä–µ–∫–ª–∞–¥—ñ–≤** - uk.json vs en.json")
    report.append("5. **–î–æ–¥–∞—Ç–∏ missing translation keys** - —É–Ω–∏–∫–Ω—É—Ç–∏ –ø–æ–º–∏–ª–æ–∫ –≤ runtime")
    report.append("")
    
    return "\n".join(report)

def main():
    if len(sys.argv) < 2:
        print("Usage: python smart_audit_v6_ultimate_plus.py <project_root>")
        sys.exit(1)
    
    project_root = sys.argv[1]
    auditor = UltimatePlusAuditor(project_root)
    issues = auditor.audit()
    
    report = generate_report(issues)
    
    # –ó–±–µ—Ä–µ–≥—Ç–∏ –∑–≤—ñ—Ç
    output_file = Path(project_root) / "audit_report_v6_ultimate_plus.md"
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(report)
    
    print(f"‚úÖ –ê—É–¥–∏—Ç –∑–∞–≤–µ—Ä—à–µ–Ω–æ! –ó–≤—ñ—Ç –∑–±–µ—Ä–µ–∂–µ–Ω–æ: {output_file}")
    print(f"üìä –ó–Ω–∞–π–¥–µ–Ω–æ –ø—Ä–æ–±–ª–µ–º: {len(issues)}")
    
    # –ü–æ–∫–∞–∑–∞—Ç–∏ —Ç–æ–ø-5 –∫—Ä–∏—Ç–∏—á–Ω–∏—Ö –ø—Ä–æ–±–ª–µ–º
    critical = [i for i in issues if i.severity == 'CRITICAL']
    if critical:
        print("\nüö® –¢–û–ü –ö–†–ò–¢–ò–ß–ù–Ü –ü–†–û–ë–õ–ï–ú–ò:")
        for i, issue in enumerate(critical[:5], 1):
            print(f"{i}. {issue.description} ({issue.file_path}:{issue.line_number})")

if __name__ == "__main__":
    main()